{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6797f98a-7ed1-4894-ab03-9edb0fbe0f29",
   "metadata": {},
   "source": [
    "# ðŸš€ Customize `Qwen/Qwen3-1.7B` for tool calling using `GRPO` and `RLVR` on Amazon SageMaker AI\n",
    "---\n",
    "In this notebook, we explore **Qwen3-1.7B**, a 1.7-billion-parameter language model from Alibaba's Qwen series. You'll learn how to fine-tune it on sample data, evaluate its reasoning, math, and coding capabilities, and deploy it at scale with SageMaker.\n",
    "\n",
    "**What is Qwen3-1.7B?**\n",
    "\n",
    "Qwen3-1.7B is part of the latest generation of Qwen models, featuring seamless switching between thinking mode for complex logical reasoning and non-thinking mode for efficient general-purpose dialogue within a single model . The model was trained on approximately 36 trillion tokens with content sourced from diverse domains supporting 119 languages . Qwen3-1.7B uses a strong-to-weak distillation process from larger Qwen3 models, transferring advanced reasoning skills from frontier models down to this lightweight version . It is released under the **Apache-2.0 license** and is fully open-weight.  \n",
    "ðŸ”— Model card: [Qwen/Qwen3-1.7B on Hugging Face](https://huggingface.co/Qwen/Qwen3-1.7B)\n",
    "\n",
    "---\n",
    "\n",
    "**Key Specifications**\n",
    "\n",
    "| Feature | Details |\n",
    "|---|---|\n",
    "| **Parameters** | â‰ˆ 1.7 billion total parameters; â‰ˆ 1.4 billion non-embedding parameters |\n",
    "| **Architecture** | Transformer with RoPE embeddings, SwiGLU activation, RMSNorm, QK-Norm, and Grouped-Query Attention |\n",
    "| **Attention Heads / GQA** | Grouped-Query Attention: 16 heads for Q, 8 heads for K/V |\n",
    "| **Layers** | 28 layers |\n",
    "| **Context Length** | Up to **32,768 tokens** |\n",
    "| **Vocabulary** | 151,669 tokens (byte-level BPE) |\n",
    "| **Modalities** | Text-in / Text-out only (no vision) |\n",
    "| **License** | Apache-2.0 |\n",
    "\n",
    "---\n",
    "\n",
    "**Benchmarks & Behavior**\n",
    "\n",
    "- Qwen3-1.7B outperforms larger Qwen2.5-3B models on over half of the benchmarks, especially on STEM-related and coding benchmarks .\n",
    "- The model demonstrates significant enhancement in reasoning capabilities, surpassing previous Qwen2.5 instruct models on mathematics, code generation, and commonsense logical reasoning .\n",
    "- Qwen3-1.7B operates in two distinct modes: thinking mode for step-by-step reasoning with intermediate computations, and non-thinking mode for rapid direct responses .\n",
    "- The model shows strong performance in human preference alignment for creative writing, instruction following, and multi-turn dialog .\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84940445-33cc-49c0-9cf5-9882062cb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uq \"datasets==4.3.0\" \\\n",
    "    \"sagemaker==2.253.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637be005-3c5b-48f3-9dc4-c72f55e35fe6",
   "metadata": {},
   "source": [
    "## 00. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d44d9c-362c-4d7f-acc5-5106465e819b",
   "metadata": {},
   "source": [
    "We start off by setting up session information such as `sagemaker.Session(...)`, region, sagemaker execution role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052316cc-0f18-4a12-96f9-89376bde3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ae411-08a1-4da5-8204-62389edee994",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "\n",
    "sess = sagemaker.Session(boto3.Session(region_name=region))\n",
    "\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd2547e-e7e6-4638-ad3a-1c3ee95f7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae9a21e-2e64-40f2-b4a4-176b929c997d",
   "metadata": {},
   "source": [
    "## 01. Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8507d221-c00b-46d8-9e89-c2999ffbbc4b",
   "metadata": {},
   "source": [
    "To fine-tune a target model on domain/task tool call - we need a sample domain dataset that has the following structure,\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"prompt\": [\n",
    "    {\n",
    "      \"content\": \"You are a ...\",\n",
    "      \"role\": \"system\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"Single income $78k, $720 ...\",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ],\n",
    "  \"answer\": \"Max Price: $384,111, ...\",\n",
    "}\n",
    "```\n",
    "\n",
    "The most important components is the,\n",
    "1. The system prompt that sets up the global model behavior \n",
    "2. User input prompt/question\n",
    "3. The final model response - which is used by the model and trainer to tune the model to select the appropriate tool to achieve the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147cce88-5593-47f5-b35c-1fbc4e2b6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from datasets import Dataset\n",
    "from sagemaker_code.tools_funcs.financial_tools_complex import run_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d0733-8318-4299-ade7-170a34eda69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a financial planning assistant with tools for portfolio allocation, mortgage affordability, tax optimization, retirement readiness, debt payoff strategies, insurance needs, education funding, and currency exchange. \n",
    "Analyze user requests and call the appropriate tool with all required parameters extracted from their query. \n",
    "Return concise answers with key metrics. Do not ask for clarification - use reasonable defaults if needed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1fdd2-28ba-468d-a589-a8e6f9ad6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "with open(\"sample_dataset/raw_financial_training_data.jsonl\", \"r\") as f:\n",
    "    raw_data = [json.loads(line) for line in f]\n",
    "\n",
    "random.shuffle(raw_data)\n",
    "print(f\"Loaded {len(raw_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c05f5-e05a-47e7-b8ca-d8db7b0d5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(raw_data) * 0.91)\n",
    "train_data = raw_data[:split_idx]\n",
    "test_data = raw_data[split_idx:]\n",
    "print(f\"Train: {len(train_data)}, Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ecdfd-bbb8-4869-b843-4d2e4692982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process training data\n",
    "train_samples = []\n",
    "for item in train_data:\n",
    "    # Execute tool to get answer\n",
    "    answer = run_tool(item[\"tool_call\"])\n",
    "    if not answer.startswith(\"Error\"):\n",
    "        train_samples.append({\n",
    "            \"prompt\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": item[\"prompt\"]},\n",
    "            ],\n",
    "            \"answer\": answer\n",
    "        })\n",
    "\n",
    "print(f\"Processed {len(train_samples)} training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f238af8-f7ab-471f-bbba-3808e6c914c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process validation data (includes ground_truth for validation)\n",
    "test_samples = []\n",
    "for item in test_data:\n",
    "    # Execute tool to get answer\n",
    "    answer = run_tool(item[\"tool_call\"])\n",
    "    if not answer.startswith(\"Error\"):\n",
    "        test_samples.append({\n",
    "            \"prompt\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": item[\"prompt\"]},\n",
    "            ],\n",
    "            \"answer\": answer,\n",
    "            \"ground_truth\": item[\"tool_call\"]\n",
    "        })\n",
    "\n",
    "print(f\"Processed {len(test_samples)} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185d584-e569-4de6-ab6c-d0595d85a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save using datasets library\n",
    "train_dataset = Dataset.from_list(train_samples)\n",
    "test_dataset = Dataset.from_list(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135dd35-7945-49a4-bdf2-48df300c6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_path = \"./sample_dataset/grpo_financial_train.jsonl\"\n",
    "os.makedirs(os.path.dirname(training_dataset_path), exist_ok=True)\n",
    "train_dataset.to_json(training_dataset_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11869e9a-5a2a-4c25-9178-d805342b54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = \"./sample_dataset/grpo_financial_test.jsonl\"\n",
    "test_dataset.to_json(test_dataset_path, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3122b-fb22-440e-a3f0-02f5fa656448",
   "metadata": {},
   "source": [
    "### Upload Training dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58001ac2-6795-4745-9e91-207f6b5ccaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sagemaker.s3 import S3Uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f78041-765a-45ff-be49-20284bc9dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s3_uri = f\"s3://{sess.default_bucket()}/tool-calling/grpo/qwen3/{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "uploaded_s3_uri = S3Uploader.upload(\n",
    "    local_path=training_dataset_path,\n",
    "    desired_s3_uri=data_s3_uri\n",
    ")\n",
    "print(f\"Uploaded {training_dataset_path} to > {uploaded_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef316a-9151-4d61-8842-c468c0b99d33",
   "metadata": {},
   "source": [
    "## Fine-Tune Language Model using SageMaker `ModelTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01228cfc-9104-411c-9ff2-afe0dd174d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.modules.configs import (\n",
    "    CheckpointConfig,\n",
    "    Compute,\n",
    "    OutputDataConfig,\n",
    "    SourceCode,\n",
    "    StoppingCondition,\n",
    ")\n",
    "from sagemaker.modules.configs import InputData\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "from getpass import getpass\n",
    "import yaml\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacaef07-ced1-42fd-9b84-2f079f22238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"Qwen/Qwen3-1.7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a42768-0416-4e0d-9ef7-39cb5eed3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_SERVER_ARN = \"arn:aws:sagemaker:<region>:XXXXX:mlflow-tracking-server/demo-name\" # or None\n",
    "\n",
    "if MLFLOW_TRACKING_SERVER_ARN:\n",
    "    reports_to = \"mlflow\"\n",
    "else:\n",
    "    reports_to = \"tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37df85-8954-49a1-860d-b776e6f55e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = MODEL_ID.replace('/', '--').replace('.', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4366b-fd33-49d2-98d9-3584da644550",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLFLOW_TRACKING_SERVER_ARN:\n",
    "    training_env = {\n",
    "        # mlflow tracking metrics\n",
    "        \"MLFLOW_EXPERIMENT_NAME\": job_name,\n",
    "        \"MLFLOW_TAGS\": json.dumps(\n",
    "            {\n",
    "                \"source.job\": \"sm-training-jobs\", \n",
    "                \"source.type\": \"trl-grpo-rlvr\", \n",
    "                \"source.framework\": \"pytorch\"\n",
    "            }\n",
    "        ),\n",
    "        \"MLFLOW_TRACKING_URI\": MLFLOW_TRACKING_SERVER_ARN,\n",
    "        \"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\": \"true\",\n",
    "        # \"HF_TOKEN\": hf_token,\n",
    "        \"FI_EFA_USE_DEVICE_RDMA\": \"1\",\n",
    "        \"NCCL_DEBUG\": \"INFO\",\n",
    "        \"NCCL_SOCKET_IFNAME\": \"eth0\",\n",
    "        \"FI_PROVIDER\": \"efa\",\n",
    "        \"NCCL_PROTO\": \"simple\",\n",
    "        \"NCCL_NET_GDR_LEVEL\": \"5\"\n",
    "    }\n",
    "else:\n",
    "    training_env = {\n",
    "        # \"HF_TOKEN\": hf_token,\n",
    "        \"FI_EFA_USE_DEVICE_RDMA\": \"1\",\n",
    "        \"NCCL_DEBUG\": \"INFO\",\n",
    "        \"NCCL_SOCKET_IFNAME\": \"eth0\",\n",
    "        \"FI_PROVIDER\": \"efa\",\n",
    "        \"NCCL_PROTO\": \"simple\",\n",
    "        \"NCCL_NET_GDR_LEVEL\": \"5\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f5d19-b4bf-4e52-952b-f60ab6ef9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sagemaker_code/requirements.txt\n",
    "git+https://github.com/huggingface/transformers.git\n",
    "git+https://github.com/huggingface/trl.git\n",
    "peft\n",
    "accelerate==1.11.0\n",
    "bitsandbytes==0.46.1\n",
    "datasets==4.0.0\n",
    "deepspeed==0.16.4\n",
    "hf-transfer==0.1.8\n",
    "hf_xet\n",
    "liger-kernel==0.6.1\n",
    "lm-eval[api]==0.4.9\n",
    "kernels>=0.9.0\n",
    "mlflow\n",
    "Pillow\n",
    "safetensors>=0.6.2\n",
    "sagemaker==2.251.1\n",
    "sagemaker-mlflow==0.1.0\n",
    "sentencepiece==0.2.0\n",
    "tokenizers>=0.21.4\n",
    "triton\n",
    "tensorboard\n",
    "psutil\n",
    "py7zr\n",
    "git+https://github.com/triton-lang/triton.git@main#subdirectory=python/triton_kernels\n",
    "vllm==0.11.0\n",
    "poetry\n",
    "yq\n",
    "psutil\n",
    "nvidia-ml-py\n",
    "pyrsmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc75a16-538b-4d50-a976-4913b67c9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PeFT\n",
    "args = [\n",
    "    \"--config\",\n",
    "    \"hf_recipes/Qwen/Qwen3-1.7B--grpo.yaml\",\n",
    "    \"--tools_script\",\n",
    "    \"tools_funcs/financial_tools_complex.py\",\n",
    "    \"--reward_fn\",\n",
    "    \"rewards/financial_tools_reward.py\",\n",
    "]\n",
    "training_instance_type = \"ml.g6e.8xlarge\"\n",
    "training_instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8915849-c38a-4091-8a6c-542701fdce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sess.boto_session.region_name,\n",
    "    version=\"2.8.0\",\n",
    "    instance_type=training_instance_type,\n",
    "    image_scope=\"training\",\n",
    ")\n",
    "print(f\"Using image: {pytorch_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f44efc-4c7e-4ac9-abe3-ac802394b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_code = SourceCode(\n",
    "    source_dir=\"./sagemaker_code\",\n",
    "    command=f\"bash sm_accelerate_grpo_train.sh {' '.join(args)}\",\n",
    ")\n",
    "\n",
    "compute_configs = Compute(\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=training_instance_count,\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    volume_size_in_gb=450\n",
    ")\n",
    "\n",
    "base_job_name = f\"{job_name}-finetune\"\n",
    "output_path = f\"s3://{sess.default_bucket()}/{base_job_name}\"\n",
    "\n",
    "model_trainer = ModelTrainer(\n",
    "    training_image=pytorch_image_uri,\n",
    "    source_code=source_code,\n",
    "    base_job_name=base_job_name,\n",
    "    compute=compute_configs,\n",
    "    stopping_condition=StoppingCondition(max_runtime_in_seconds=18000),\n",
    "    output_data_config=OutputDataConfig(\n",
    "        s3_output_path=output_path,\n",
    "    ),\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        s3_uri=os.path.join(\n",
    "            output_path,\n",
    "            \"financial-api-for-tool-calling\", \n",
    "            job_name,\n",
    "            \"checkpoints\"\n",
    "        ), \n",
    "        local_path=\"/opt/ml/checkpoints\"\n",
    "    ),\n",
    "    role=role,\n",
    "    environment=training_env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a19463-1541-4f77-8dd7-997a5037a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.train(\n",
    "    input_data_config=[\n",
    "        InputData(\n",
    "            channel_name=\"training\",\n",
    "            data_source=uploaded_s3_uri,  \n",
    "        )\n",
    "    ], \n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48918f-ff63-4b30-9448-dcd3cc9b69fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
