{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e60b91a9-7d9c-4c45-be0f-5a224581f644",
            "metadata": {},
            "source": [
                "# ðŸš€ Customize and Deploy `deepseek-ai/DeepSeek-R1-0528` on Amazon SageMaker AI\n",
                "\n",
                "In this notebook, we explore **DeepSeek-R1-0528**, a cutting-edge reasoning model from DeepSeek AI. You'll learn how to fine-tune it on reasoning datasets, evaluate its mathematical and logical capabilities, and deploy it using SageMaker for advanced reasoning tasks.\n",
                "\n",
                "## What is DeepSeek-R1-0528?\n",
                "DeepSeek-R1-0528 is part of DeepSeek's R1 series, specifically designed for advanced reasoning capabilities. This model represents a significant advancement in AI reasoning, combining deep learning with sophisticated reasoning mechanisms to tackle complex mathematical, logical, and analytical problems. It builds upon DeepSeek's expertise in creating efficient and powerful language models.  \n",
                "ðŸ”— Model card: [deepseek-ai/DeepSeek-R1-0528 on Hugging Face](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528)\n",
                "\n",
                "## Key Specifications\n",
                "| Feature | Details |\n",
                "|---|---|\n",
                "| **Parameters** | Multi-billion parameter architecture optimized for reasoning |\n",
                "| **Architecture** | Advanced Transformer with specialized reasoning modules |\n",
                "| **Context Length** | Extended context window for complex reasoning chains |\n",
                "| **Modalities** | Text-in / Text-out with focus on reasoning tasks |\n",
                "| **License** | Check model card for specific licensing terms |\n",
                "| **Release Date** | May 28th release (0528) |\n",
                "\n",
                "## Benchmarks & Behavior\n",
                "- Exceptional performance on **mathematical reasoning, logical inference, and complex problem-solving** benchmarks.  \n",
                "- Designed to excel at **multi-step reasoning tasks** with clear chain-of-thought capabilities.  \n",
                "- Strong performance on competition mathematics, coding challenges, and analytical reasoning tasks.  \n",
                "- Optimized for **step-by-step problem decomposition** and systematic solution approaches.  \n",
                "\n",
                "## Using This Notebook\n",
                "You'll cover:\n",
                "* Load the NuminaMath-CoT reasoning dataset from Hugging Face and prepare it for fine-tuning  \n",
                "* Fine-tune with SageMaker Training Jobs using reasoning-optimized configurations  \n",
                "* Run model evaluation on mathematical reasoning benchmarks  \n",
                "* Deploy to SageMaker Endpoints for production reasoning tasks  \n",
                "\n",
                "Let's begin by exploring `deepseek-ai/DeepSeek-R1-0528` and testing its baseline reasoning performance with mathematical problems.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "install_packages",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/home/ubuntu/py312-training/bin/python3: No module named pip\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install -Uq sagemaker datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "import_libs",
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'sagemaker'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mboto3\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msagemaker\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sagemaker'"
                    ]
                }
            ],
            "source": [
                "import boto3\n",
                "import sagemaker\n",
                "import time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "session_setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "region = boto3.Session().region_name\n",
                "sess = sagemaker.Session(boto3.Session(region_name=region))\n",
                "\n",
                "sagemaker_session_bucket = sess.default_bucket()\n",
                "role = sagemaker.get_execution_role()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "print_env",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"sagemaker role arn: {role}\")\n",
                "print(f\"sagemaker bucket: {sagemaker_session_bucket}\")\n",
                "print(f\"sagemaker session region: {sess.boto_region_name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dataset_intro",
            "metadata": {},
            "source": [
                "### [NuminaMath-CoT](https://huggingface.co/datasets/AI-MO/NuminaMath-CoT)\n",
                "\n",
                "**NuminaMath-CoT** is a large-scale dataset of **~860,000+ math competition question-solution pairs**, designed to support chain-of-thought reasoning in mathematical problem solving.\n",
                "\n",
                "**Data Format & Structure**:\n",
                "- Each example is a question followed by a solution; the solution is formatted with detailed **Chain-of-Thought (CoT)** reasoning.  \n",
                "- The data sources include *Chinese high school math exercises*, *US and international mathematics competition problems*, *online test-papers PDFs*, and *math discussion forums*.  \n",
                "- Preprocessing includes OCR from PDFs, segmentation to extract problem-solution pairs, translation into English, alignment into CoT style, and formatting of final answers.  \n",
                "\n",
                "**License**: Released under the **Apache-2.0** license.  \n",
                "\n",
                "**Applications**:\n",
                "\n",
                "This dataset is useful for training and evaluating models on tasks including:  \n",
                "- Complex math problem solving with reasoning steps (algebra, geometry, number theory, etc.)  \n",
                "- Benchmarking chain-of-thought performance of LLMs on competition-level math tasks  \n",
                "- Educational tools and tutoring systems that require explainable math solutions  \n",
                "- Fine-tuning models to improve consistency, reasoning depth, and accuracy in mathematical domains  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "3930cfd8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import pprint\n",
                "from tqdm import tqdm\n",
                "from datasets import load_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "411b39d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_parent_path = os.path.join(os.getcwd(), \"tmp_cache_local_dataset\")\n",
                "os.makedirs(dataset_parent_path, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2556c059",
            "metadata": {},
            "source": [
                "**Preparing Your Dataset in `messages` format**\n",
                "\n",
                "This section walks you through creating a conversation-style datasetâ€”the required `messages` formatâ€”for directly training LLMs using SageMaker AI.\n",
                "\n",
                "**What Is the `messages` Format?**\n",
                "\n",
                "The `messages` format structures instances as chat-like exchanges, wrapping each conversation turn into a role-labeled JSON array. Itâ€™s widely used by frameworks like TRL.\n",
                "\n",
                "Example entry:\n",
                "\n",
                "```json\n",
                "{\n",
                "  \"messages\": [\n",
                "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
                "    { \"role\": \"user\", \"content\": \"How do I bake sourdough?\" },\n",
                "    { \"role\": \"assistant\", \"content\": \"First, you need to create a starter by...\" }\n",
                "  ]\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "7d8c3f1a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "be57ce8d75dc4af1ac299eaad6bf3db6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "README.md: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6882a2b91ddf471a883bea43128ba741",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "data/train-00000-of-00005.parquet:   0%|          | 0.00/247M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5d477de6c53b4f5a867f5c0dd3e97835",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "data/train-00001-of-00005.parquet:   0%|          | 0.00/247M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f8b223ff78cb4aafbef253d3e7abc488",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "data/train-00002-of-00005.parquet:   0%|          | 0.00/247M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2768c2e7cb7641b3812214d4f06e058c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "data/train-00003-of-00005.parquet:   0%|          | 0.00/247M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2720af22ce20471a9d7adabaa71fa572",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "data/train-00004-of-00005.parquet:   0%|          | 0.00/247M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "60ab19d27afd4dd28a2fc186b992e80d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "data/test-00000-of-00001.parquet:   0%|          | 0.00/166k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0e26709e6b624f7dac533a7c7124b5cc",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating train split:   0%|          | 0/859494 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6516d1f3472046bc8e6401392b6eb40e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "dataset_name = \"AI-MO/NuminaMath-CoT\"\n",
                "dataset = load_dataset(dataset_name, split=\"train[:1000]\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "64240a30",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'source': 'synthetic_math',\n",
                        " 'problem': 'Consider the terms of an arithmetic sequence: $-\\\\frac{1}{3}, '\n",
                        "            'y+2, 4y, \\\\ldots$. Solve for $y$.',\n",
                        " 'solution': 'For an arithmetic sequence, the difference between consecutive '\n",
                        "             'terms must be equal. Therefore, we can set up the following '\n",
                        "             'equations based on the sequence given:\\n'\n",
                        "             '\\\\[ (y + 2) - \\\\left(-\\\\frac{1}{3}\\\\right) = 4y - (y+2) \\\\]\\n'\n",
                        "             '\\n'\n",
                        "             'Simplify and solve these equations:\\n'\n",
                        "             '\\\\[ y + 2 + \\\\frac{1}{3} = 4y - y - 2 \\\\]\\n'\n",
                        "             '\\\\[ y + \\\\frac{7}{3} = 3y - 2 \\\\]\\n'\n",
                        "             '\\\\[ \\\\frac{7}{3} + 2 = 3y - y \\\\]\\n'\n",
                        "             '\\\\[ \\\\frac{13}{3} = 2y \\\\]\\n'\n",
                        "             '\\\\[ y = \\\\frac{13}{6} \\\\]\\n'\n",
                        "             '\\n'\n",
                        "             'Thus, the value of $y$ that satisfies the given arithmetic '\n",
                        "             'sequence is $\\\\boxed{\\\\frac{13}{6}}$.',\n",
                        " 'messages': [{'content': 'Consider the terms of an arithmetic sequence: '\n",
                        "                          '$-\\\\frac{1}{3}, y+2, 4y, \\\\ldots$. Solve for $y$.',\n",
                        "               'role': 'user'},\n",
                        "              {'content': 'For an arithmetic sequence, the difference between '\n",
                        "                          'consecutive terms must be equal. Therefore, we can '\n",
                        "                          'set up the following equations based on the '\n",
                        "                          'sequence given:\\n'\n",
                        "                          '\\\\[ (y + 2) - \\\\left(-\\\\frac{1}{3}\\\\right) = 4y - '\n",
                        "                          '(y+2) \\\\]\\n'\n",
                        "                          '\\n'\n",
                        "                          'Simplify and solve these equations:\\n'\n",
                        "                          '\\\\[ y + 2 + \\\\frac{1}{3} = 4y - y - 2 \\\\]\\n'\n",
                        "                          '\\\\[ y + \\\\frac{7}{3} = 3y - 2 \\\\]\\n'\n",
                        "                          '\\\\[ \\\\frac{7}{3} + 2 = 3y - y \\\\]\\n'\n",
                        "                          '\\\\[ \\\\frac{13}{3} = 2y \\\\]\\n'\n",
                        "                          '\\\\[ y = \\\\frac{13}{6} \\\\]\\n'\n",
                        "                          '\\n'\n",
                        "                          'Thus, the value of $y$ that satisfies the given '\n",
                        "                          'arithmetic sequence is $\\\\boxed{\\\\frac{13}{6}}$.',\n",
                        "               'role': 'assistant'}]}\n"
                    ]
                }
            ],
            "source": [
                "pprint.pp(dataset[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "a0aa47d2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "total number of fine-tunable samples: 1000\n"
                    ]
                }
            ],
            "source": [
                "print(f\"total number of fine-tunable samples: {len(dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "8c14548c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4607ca1f5f5d44458506dd9a10508a20",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "def convert_to_messages_reasoning(row):\n",
                "    system_content = \"You are a mathematical reasoning assistant. Read the problem, restate the key givens and goal, then solve step-by-step with clear algebra (use LaTeX), keeping exact arithmetic (fractions/surds) and justifying each transformation (e.g., equal differences for arithmetic sequences). Verify any domain or extraneous-solution constraints, and present the final simplified answer concisely on the last line.\"\n",
                "    \n",
                "    messages_user_row = row[\"messages\"][0]\n",
                "    assert messages_user_row[\"role\"] == \"user\", f\"user row unmatched\"\n",
                "    user_content = messages_user_row[\"content\"]\n",
                "    \n",
                "    messages_assistant_row = row[\"messages\"][1]\n",
                "    assert messages_assistant_row[\"role\"] == \"assistant\", f\"assistant row unmatched\"\n",
                "    assistant_content = messages_assistant_row[\"content\"]\n",
                "\n",
                "    think_block = f\"<think>{row['solution']}</think>\"\n",
                "    \n",
                "    return {\n",
                "        \"messages\": [\n",
                "            { \"role\": \"system\", \"content\": system_content},\n",
                "            { \"role\": \"user\", \"content\": user_content },\n",
                "            { \"role\": \"assistant\", \"content\": f\"{think_block}\\n\\n{assistant_content}\" }\n",
                "        ]\n",
                "    }\n",
                "    \n",
                "    \n",
                "dataset = dataset.map(convert_to_messages_reasoning, remove_columns=dataset.column_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "cfb84faf",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fed54a44b27f4b4eb835db0b2b7b3f1c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "3243521"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dataset_filename = os.path.join(dataset_parent_path, f\"{dataset_name.replace('/', '--').replace('.', '-')}.jsonl\")\n",
                "dataset.to_json(dataset_filename, lines=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "upload_s3_section",
            "metadata": {},
            "source": [
                "#### Upload file to S3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "s3_uploader_import",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sagemaker.s3 import S3Uploader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "upload_to_s3",
            "metadata": {},
            "outputs": [],
            "source": [
                "data_s3_uri = f\"s3://{sess.default_bucket()}/dataset\"\n",
                "\n",
                "uploaded_s3_uri = S3Uploader.upload(\n",
                "    local_path=dataset_filename,\n",
                "    desired_s3_uri=data_s3_uri\n",
                ")\n",
                "print(f\"Uploaded {dataset_filename} to > {uploaded_s3_uri}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "training_section",
            "metadata": {},
            "source": [
                "## Fine-Tune LLMs using SageMaker `Estimator`/`ModelTrainer`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "training_imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "from sagemaker.pytorch import PyTorch\n",
                "from getpass import getpass\n",
                "import yaml\n",
                "from jinja2 import Template"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "hf_token_input",
            "metadata": {},
            "outputs": [],
            "source": [
                "hf_token = getpass()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pytorch_estimator_section",
            "metadata": {},
            "source": [
                "### Training using `PyTorch` Estimator"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "pytorch_description",
            "metadata": {},
            "source": [
                "**Training Using `PyTorch` Estimator**\n",
                "Leverages the official PyTorch SageMaker container to run a custom training script using the Accelerate and DeepSpeed libraries. This option is ideal for users who want full control over the training pipeline for DeepSeek-R1-0528's reasoning capabilities."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "pytorch_config_setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_id = \"deepseek-ai/DeepSeek-R1-0528\"\n",
                "model_name = model_id.split(\"/\")[-1]\n",
                "\n",
                "# Training configuration optimized for reasoning tasks\n",
                "training_config = {\n",
                "    \"model_id\": model_id,\n",
                "    \"dataset_path\": \"/opt/ml/input/data/training\",\n",
                "    \"num_train_epochs\": 3,\n",
                "    \"per_device_train_batch_size\": 1,\n",
                "    \"gradient_accumulation_steps\": 8,\n",
                "    \"learning_rate\": 2e-5,\n",
                "    \"max_seq_len\": 2048,\n",
                "    \"packing\": False,\n",
                "    \"use_flash_attention_2\": True,\n",
                "    \"merge_adapters\": True,\n",
                "    \"bf16\": True,\n",
                "    \"tf32\": True,\n",
                "    \"gradient_checkpointing\": True,\n",
                "    \"logging_steps\": 10,\n",
                "    \"save_strategy\": \"epoch\",\n",
                "    \"output_dir\": \"/opt/ml/model\",\n",
                "    \"optim\": \"adamw_torch\",\n",
                "    \"lr_scheduler_type\": \"cosine\",\n",
                "    \"warmup_ratio\": 0.1,\n",
                "    \"seed\": 42\n",
                "}\n",
                "\n",
                "print(f\"Training DeepSeek-R1-0528 with configuration:\")\n",
                "for key, value in training_config.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "pytorch_estimator_creation",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create PyTorch estimator for DeepSeek-R1-0528\n",
                "pytorch_estimator = PyTorch(\n",
                "    entry_point=\"sft.py\",\n",
                "    source_dir=\"sagemaker_code\",\n",
                "    role=role,\n",
                "    instance_type=\"ml.g5.2xlarge\",  # Adjust based on model size and requirements\n",
                "    instance_count=1,\n",
                "    framework_version=\"2.0.1\",\n",
                "    py_version=\"py310\",\n",
                "    hyperparameters=training_config,\n",
                "    environment={\n",
                "        \"HUGGINGFACE_HUB_CACHE\": \"/opt/ml/input/data/cache\",\n",
                "        \"HF_TOKEN\": hf_token,\n",
                "        \"TRANSFORMERS_CACHE\": \"/opt/ml/input/data/cache\",\n",
                "        \"ACCELERATE_USE_FSDP\": \"0\",\n",
                "        \"FSDP_CPU_RAM_EFFICIENT_LOADING\": \"1\"\n",
                "    },\n",
                "    disable_output_compression=True,\n",
                "    keep_alive_period_in_seconds=1800,\n",
                "    volume_size=100\n",
                ")\n",
                "\n",
                "print(f\"Created PyTorch estimator for {model_id}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "pytorch_training_start",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start training\n",
                "training_job_name = f\"deepseek-r1-0528-reasoning-{int(time.time())}\"\n",
                "\n",
                "pytorch_estimator.fit(\n",
                "    inputs={\n",
                "        \"training\": uploaded_s3_uri\n",
                "    },\n",
                "    job_name=training_job_name,\n",
                "    wait=False\n",
                ")\n",
                "\n",
                "print(f\"Training job '{training_job_name}' started for DeepSeek-R1-0528\")\n",
                "print(f\"Monitor progress in SageMaker console or use: pytorch_estimator.logs()\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "huggingface_estimator_section",
            "metadata": {},
            "source": [
                "### Training using Hugging Face `Estimator`"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "huggingface_description",
            "metadata": {},
            "source": [
                "**Training Using Hugging Face `Estimator`**\n",
                "Uses the Hugging Face SageMaker container with TRL (Transformer Reinforcement Learning) for streamlined fine-tuning. This approach provides optimized defaults for reasoning models like DeepSeek-R1-0528."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "huggingface_imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sagemaker.huggingface import HuggingFace"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "huggingface_config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hugging Face training configuration for reasoning tasks\n",
                "hf_training_config = {\n",
                "    \"model_id\": model_id,\n",
                "    \"dataset_path\": \"/opt/ml/input/data/training\",\n",
                "    \"num_train_epochs\": 2,\n",
                "    \"per_device_train_batch_size\": 1,\n",
                "    \"gradient_accumulation_steps\": 16,\n",
                "    \"learning_rate\": 1e-5,\n",
                "    \"max_seq_len\": 2048,\n",
                "    \"packing\": True,\n",
                "    \"use_flash_attention_2\": True,\n",
                "    \"merge_adapters\": True,\n",
                "    \"bf16\": True,\n",
                "    \"tf32\": True,\n",
                "    \"gradient_checkpointing\": True,\n",
                "    \"logging_steps\": 5,\n",
                "    \"save_strategy\": \"epoch\",\n",
                "    \"output_dir\": \"/opt/ml/model\",\n",
                "    \"optim\": \"adamw_8bit\",\n",
                "    \"lr_scheduler_type\": \"linear\",\n",
                "    \"warmup_steps\": 100,\n",
                "    \"seed\": 42,\n",
                "    \"use_lora\": True,\n",
                "    \"lora_r\": 64,\n",
                "    \"lora_alpha\": 16,\n",
                "    \"lora_dropout\": 0.1,\n",
                "    \"target_modules\": \"all-linear\"\n",
                "}\n",
                "\n",
                "print(f\"Hugging Face training configuration for DeepSeek-R1-0528:\")\n",
                "for key, value in hf_training_config.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "huggingface_estimator_creation",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Hugging Face estimator\n",
                "huggingface_estimator = HuggingFace(\n",
                "    entry_point=\"sft.py\",\n",
                "    source_dir=\"sagemaker_code\",\n",
                "    role=role,\n",
                "    instance_type=\"ml.g5.xlarge\",\n",
                "    instance_count=1,\n",
                "    transformers_version=\"4.36.0\",\n",
                "    pytorch_version=\"2.1.0\",\n",
                "    py_version=\"py310\",\n",
                "    hyperparameters=hf_training_config,\n",
                "    environment={\n",
                "        \"HUGGINGFACE_HUB_CACHE\": \"/opt/ml/input/data/cache\",\n",
                "        \"HF_TOKEN\": hf_token,\n",
                "        \"TRANSFORMERS_CACHE\": \"/opt/ml/input/data/cache\"\n",
                "    },\n",
                "    disable_output_compression=True,\n",
                "    volume_size=80\n",
                ")\n",
                "\n",
                "print(f\"Created Hugging Face estimator for {model_id}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "huggingface_training_start",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start Hugging Face training\n",
                "hf_training_job_name = f\"deepseek-r1-0528-hf-reasoning-{int(time.time())}\"\n",
                "\n",
                "huggingface_estimator.fit(\n",
                "    inputs={\n",
                "        \"training\": uploaded_s3_uri\n",
                "    },\n",
                "    job_name=hf_training_job_name,\n",
                "    wait=False\n",
                ")\n",
                "\n",
                "print(f\"Hugging Face training job '{hf_training_job_name}' started\")\n",
                "print(f\"Monitor progress: huggingface_estimator.logs()\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "jumpstart_section",
            "metadata": {},
            "source": [
                "### Training using SageMaker JumpStart"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "jumpstart_description",
            "metadata": {},
            "source": [
                "**Training Using SageMaker JumpStart**\n",
                "Provides a managed training experience with pre-configured settings optimized for popular models. While DeepSeek-R1-0528 may not be directly available in JumpStart, this section shows how to adapt the approach for reasoning model fine-tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "jumpstart_imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sagemaker.jumpstart.model import JumpStartModel\n",
                "from sagemaker.jumpstart.estimator import JumpStartEstimator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "jumpstart_config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Note: DeepSeek-R1-0528 may not be directly available in JumpStart\n",
                "# This example shows the pattern for when it becomes available\n",
                "\n",
                "try:\n",
                "    # Check if DeepSeek models are available in JumpStart\n",
                "    jumpstart_model_id = \"huggingface-llm-deepseek-r1-0528\"  # Hypothetical ID\n",
                "    \n",
                "    jumpstart_estimator = JumpStartEstimator(\n",
                "        model_id=jumpstart_model_id,\n",
                "        role=role,\n",
                "        instance_type=\"ml.g5.2xlarge\",\n",
                "        instance_count=1,\n",
                "        hyperparameters={\n",
                "            \"epochs\": \"3\",\n",
                "            \"learning_rate\": \"2e-5\",\n",
                "            \"train_batch_size\": \"1\",\n",
                "            \"max_input_length\": \"2048\",\n",
                "            \"validation_split_ratio\": \"0.1\",\n",
                "            \"lora_r\": \"64\",\n",
                "            \"lora_alpha\": \"16\",\n",
                "            \"lora_dropout\": \"0.1\",\n",
                "            \"bf16\": \"True\",\n",
                "            \"gradient_checkpointing\": \"True\"\n",
                "        },\n",
                "        environment={\n",
                "            \"HF_TOKEN\": hf_token\n",
                "        }\n",
                "    )\n",
                "    \n",
                "    print(f\"JumpStart estimator created for {jumpstart_model_id}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"DeepSeek-R1-0528 not yet available in JumpStart: {e}\")\n",
                "    print(\"Use PyTorch or Hugging Face estimators above for now\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "jumpstart_training_start",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment when DeepSeek-R1-0528 becomes available in JumpStart\n",
                "# jumpstart_training_job_name = f\"deepseek-r1-0528-jumpstart-{int(time.time())}\"\n",
                "\n",
                "# jumpstart_estimator.fit(\n",
                "#     inputs={\n",
                "#         \"training\": uploaded_s3_uri\n",
                "#     },\n",
                "#     job_name=jumpstart_training_job_name,\n",
                "#     wait=False\n",
                "# )\n",
                "\n",
                "print(\"JumpStart training will be available when DeepSeek-R1-0528 is added to the model catalog\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "evaluation_section",
            "metadata": {},
            "source": [
                "## Model Evaluation and Testing"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "evaluation_description",
            "metadata": {},
            "source": [
                "**Evaluating DeepSeek-R1-0528 Reasoning Performance**\n",
                "\n",
                "After fine-tuning, it's crucial to evaluate the model's reasoning capabilities on mathematical and logical tasks. This section provides evaluation frameworks specifically designed for reasoning models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "evaluation_imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score\n",
                "import re"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "evaluation_functions",
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_final_answer(response):\n",
                "    \"\"\"Extract the final answer from model response\"\"\"\n",
                "    # Look for boxed answers like \\boxed{answer}\n",
                "    boxed_pattern = r'\\\\boxed\\{([^}]+)\\}'\n",
                "    match = re.search(boxed_pattern, response)\n",
                "    if match:\n",
                "        return match.group(1).strip()\n",
                "    \n",
                "    # Look for \"The answer is\" patterns\n",
                "    answer_pattern = r'[Tt]he answer is[:\\s]*([^\\n\\.]+)'\n",
                "    match = re.search(answer_pattern, response)\n",
                "    if match:\n",
                "        return match.group(1).strip()\n",
                "    \n",
                "    # Return last line as fallback\n",
                "    lines = response.strip().split('\\n')\n",
                "    return lines[-1].strip() if lines else \"\"\n",
                "\n",
                "def evaluate_reasoning_accuracy(predictions, ground_truths):\n",
                "    \"\"\"Evaluate reasoning accuracy by comparing final answers\"\"\"\n",
                "    correct = 0\n",
                "    total = len(predictions)\n",
                "    \n",
                "    for pred, truth in zip(predictions, ground_truths):\n",
                "        pred_answer = extract_final_answer(pred)\n",
                "        truth_answer = extract_final_answer(truth)\n",
                "        \n",
                "        # Normalize answers for comparison\n",
                "        pred_normalized = re.sub(r'\\s+', '', pred_answer.lower())\n",
                "        truth_normalized = re.sub(r'\\s+', '', truth_answer.lower())\n",
                "        \n",
                "        if pred_normalized == truth_normalized:\n",
                "            correct += 1\n",
                "    \n",
                "    return correct / total if total > 0 else 0\n",
                "\n",
                "print(\"Evaluation functions defined for DeepSeek-R1-0528 reasoning assessment\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "sample_evaluation",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample evaluation on test problems\n",
                "test_problems = [\n",
                "    \"Solve for x: 2x + 5 = 13\",\n",
                "    \"Find the derivative of f(x) = x^3 + 2x^2 - 5x + 1\",\n",
                "    \"If a triangle has sides of length 3, 4, and 5, what is its area?\"\n",
                "]\n",
                "\n",
                "expected_answers = [\n",
                "    \"x = 4\",\n",
                "    \"f'(x) = 3x^2 + 4x - 5\",\n",
                "    \"6\"\n",
                "]\n",
                "\n",
                "print(\"Sample test problems for DeepSeek-R1-0528 evaluation:\")\n",
                "for i, problem in enumerate(test_problems):\n",
                "    print(f\"{i+1}. {problem}\")\n",
                "    print(f\"   Expected: {expected_answers[i]}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "deployment_section",
            "metadata": {},
            "source": [
                "## Model Deployment"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "deployment_description",
            "metadata": {},
            "source": [
                "**Deploying Fine-tuned DeepSeek-R1-0528**\n",
                "\n",
                "Deploy your fine-tuned reasoning model to SageMaker endpoints for production use. The deployment supports real-time inference for mathematical reasoning and problem-solving tasks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "deployment_config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Deploy the fine-tuned model (using PyTorch estimator as example)\n",
                "endpoint_name = f\"deepseek-r1-0528-reasoning-endpoint-{int(time.time())}\"\n",
                "\n",
                "try:\n",
                "    predictor = pytorch_estimator.deploy(\n",
                "        initial_instance_count=1,\n",
                "        instance_type=\"ml.g5.xlarge\",\n",
                "        endpoint_name=endpoint_name,\n",
                "        wait=False\n",
                "    )\n",
                "    \n",
                "    print(f\"Deploying DeepSeek-R1-0528 to endpoint: {endpoint_name}\")\n",
                "    print(\"Deployment in progress... This may take 10-15 minutes.\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Deployment error: {e}\")\n",
                "    print(\"Ensure training job completed successfully before deployment\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "inference_example",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example inference with the deployed model\n",
                "def test_reasoning_inference(predictor, problem):\n",
                "    \"\"\"Test reasoning inference with deployed model\"\"\"\n",
                "    try:\n",
                "        response = predictor.predict({\n",
                "            \"inputs\": problem,\n",
                "            \"parameters\": {\n",
                "                \"max_new_tokens\": 512,\n",
                "                \"temperature\": 0.1,\n",
                "                \"do_sample\": True,\n",
                "                \"top_p\": 0.9,\n",
                "                \"repetition_penalty\": 1.1\n",
                "            }\n",
                "        })\n",
                "        return response\n",
                "    except Exception as e:\n",
                "        return f\"Inference error: {e}\"\n",
                "\n",
                "# Test problem for reasoning\n",
                "test_problem = \"\"\"Solve the following step by step:\n",
                "A rectangular garden has a length that is 3 meters more than twice its width. \n",
                "If the perimeter is 36 meters, find the dimensions of the garden.\"\"\"\n",
                "\n",
                "print(f\"Test problem for DeepSeek-R1-0528:\")\n",
                "print(test_problem)\n",
                "print(\"\\nWaiting for endpoint deployment to complete...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cleanup_resources",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cleanup resources (uncomment when done)\n",
                "# predictor.delete_endpoint()\n",
                "# print(f\"Endpoint {endpoint_name} deleted\")\n",
                "\n",
                "print(\"Remember to delete the endpoint when finished to avoid charges:\")\n",
                "print(f\"predictor.delete_endpoint()\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "conclusion_section",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "This notebook demonstrated how to fine-tune and deploy **DeepSeek-R1-0528** for advanced reasoning tasks using Amazon SageMaker. Key highlights:\n",
                "\n",
                "### What We Accomplished:\n",
                "- **Model Understanding**: Explored DeepSeek-R1-0528's reasoning capabilities and architecture\n",
                "- **Dataset Preparation**: Processed NuminaMath-CoT for chain-of-thought reasoning training\n",
                "- **Multiple Training Strategies**: \n",
                "  - PyTorch Estimator for full control\n",
                "  - Hugging Face Estimator with TRL optimization\n",
                "  - SageMaker JumpStart (when available)\n",
                "- **Evaluation Framework**: Built reasoning-specific evaluation metrics\n",
                "- **Production Deployment**: Deployed for real-time mathematical reasoning inference\n",
                "\n",
                "### Key Benefits of DeepSeek-R1-0528:\n",
                "- **Advanced Reasoning**: Specialized architecture for multi-step logical inference\n",
                "- **Mathematical Excellence**: Strong performance on competition-level math problems\n",
                "- **Chain-of-Thought**: Natural step-by-step problem decomposition\n",
                "- **Scalable Deployment**: Efficient inference for production reasoning applications\n",
                "\n",
                "### Next Steps:\n",
                "- Experiment with different reasoning datasets (GSM8K, MATH, etc.)\n",
                "- Fine-tune on domain-specific reasoning tasks\n",
                "- Implement reasoning evaluation benchmarks\n",
                "- Explore multi-modal reasoning capabilities\n",
                "- Optimize inference performance for production workloads\n",
                "\n",
                "DeepSeek-R1-0528 represents a significant advancement in AI reasoning capabilities, making it an excellent choice for applications requiring sophisticated mathematical and logical problem-solving abilities."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}