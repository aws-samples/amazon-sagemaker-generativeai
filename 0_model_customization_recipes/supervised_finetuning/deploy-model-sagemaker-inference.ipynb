{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d726929b-c151-4883-810b-45fdd4935c0d",
   "metadata": {},
   "source": [
    "# Deploy Fine-Tuned Models with Amazon SageMaker AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43421def",
   "metadata": {},
   "source": [
    "# ðŸš€ Multi-Model Deployment with Amazon SageMaker Inference Components\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to this comprehensive guide on deploying multiple fine-tuned models using **Amazon SageMaker Real-Time Inference Endpoint**! ðŸŽ¯\n",
    "\n",
    "\n",
    "\n",
    "**ðŸ¤– SageMaker Models**: These are machine learning model artifacts that contain the trained model data, inference code, and configuration needed for making predictions. Think of them as packaged ML models ready for deployment.\n",
    "\n",
    "**ðŸŒ SageMaker Endpoints**: These are fully-managed inference endpoints that host your models and provide real-time prediction capabilities via HTTPS requests. They handle scaling, load balancing, and high availability automatically.\n",
    "\n",
    "**âš™ï¸ Inference Components**: A powerful feature that allows you to deploy multiple models on a single endpoint, enabling efficient resource utilization and cost optimization. Each component can have its own compute allocation and scaling configuration.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we'll demonstrate how to deploy **multiple fine-tuned models** that were trained on Amazon SageMaker AI. We'll show you how to:\n",
    "- Create and configure multiple SageMaker models\n",
    "- Set up inference components for efficient multi-model hosting\n",
    "- Deploy everything to a single, cost-effective endpoint\n",
    "- Test our deployed models with real inference requests\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uq \"datasets==4.3.0\" \\\n",
    "    \"sagemaker==2.253.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665879ed-8353-40c3-9ced-32c402982961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76a5e3-560b-4952-8f32-5f28cfc3957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "sagemaker_session_bucket = None\n",
    "\n",
    "if sagemaker_session_bucket is None and sagemaker_session is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.session.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "sagemaker_session = Session(default_bucket=sagemaker_session_bucket)\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=sagemaker_session.boto_region_name)\n",
    "sts = boto3.client(\"sts\", region_name=sagemaker_session.boto_region_name)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12fcc6-fac8-478f-99af-8b57677eb5e7",
   "metadata": {},
   "source": [
    "## Attach to a Completed Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e8b0b-dd71-4146-adcb-9d0cad0d482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "pytorch_estimator = Estimator.attach(\n",
    "    training_job_name=\"meta-llama--Llama-3-2-3B-Instruct-finetune-20251118054934\"\n",
    ")\n",
    "\n",
    "s3_model_data_uri = pytorch_estimator.model_data\n",
    "print(f\"Fine-tuned model location: {s3_model_data_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97bf8e-1743-49c1-a85d-0069c181de65",
   "metadata": {},
   "source": [
    "### Untar the final model weights - `model.tar.gz` and upload the weights to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d81094d-fe8a-47a6-9ffe-edb88688da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "import tarfile\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.compute_resource_requirements.resource_requirements import ResourceRequirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2980b4-2334-4558-b82b-f4b94333e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02035bec-41a2-420b-a43d-ec4d7355f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = \"/tmp/tmp_cache_local_model\"\n",
    "os.makedirs(local_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95c6c3-69e9-47ee-a91a-29a7b9426204",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3Downloader.download(\n",
    "    s3_uri=s3_model_data_uri,\n",
    "    local_path=local_model_path\n",
    ")\n",
    "print(f\"download model file to {local_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a7c2d-14c9-447b-a515-4b95b2a9fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_gpt_oss_model_path = os.path.join(local_model_path, \"gpt-oss-model-finetuned-spectrum\")\n",
    "os.makedirs(local_gpt_oss_model_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def untar_file(tar_path: str, destination: str) -> None:\n",
    "\n",
    "    if not os.path.isfile(tar_path):\n",
    "        raise FileNotFoundError(f\"The file '{tar_path}' does not exist.\")\n",
    "\n",
    "    os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=destination)\n",
    "        print(f\"Extracted '{tar_path}' to '{destination}'.\")\n",
    "\n",
    "\n",
    "# untar model file\n",
    "untar_file(\n",
    "    tar_path=os.path.join(local_model_path, os.path.basename(s3_model_data_uri)), \n",
    "    destination=local_gpt_oss_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ceea29-2a23-4d09-9365-cc23dc81d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s3_uri = os.path.join(os.path.dirname(s3_model_data_uri), \"full-model-paths\")\n",
    "\n",
    "uploaded_model_s3_uri = S3Uploader.upload(\n",
    "    local_path=local_gpt_oss_model_path,\n",
    "    desired_s3_uri=model_s3_uri\n",
    ")\n",
    "print(f\"Uploaded {local_gpt_oss_model_path} to > {uploaded_model_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3f039-2d75-4d22-af80-1e67b9394c06",
   "metadata": {},
   "source": [
    "## Deploy as a SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e472e80-d24b-47bc-966e-216dad499e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd18b1-a260-401e-a2e5-19129493ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "inference_image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.34.0-lmi16.0.0-cu128\"\n",
    "\n",
    "print(f\"inference image: {inference_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ea50a-41a4-4eed-b25f-5646de032ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = sagemaker.utils.name_from_base(f\"tuned-model\")\n",
    "inference_component_name = f\"ic-{model_name}\"\n",
    "endpoint_config_name = f\"epc-{model_name}\"\n",
    "endpoint_name = f\"ep-{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa4535-e2b6-4363-a289-3d45e476a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.g6e.2xlarge\"\n",
    "num_gpu = 1\n",
    "variant_name = \"AllTraffic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eff539-1e47-4c10-a489-2caa2b4a1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\">> Model name: {model_name}\")\n",
    "print(f\">> IC name: {inference_component_name}\")\n",
    "print(f\">> Endpoint Config name: {endpoint_config_name}\")\n",
    "print(f\">> Endpoint name: {endpoint_name}\")\n",
    "print(f\">> Instance: {instance_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0d327-23ce-487a-b370-a5f6f5b3b46b",
   "metadata": {},
   "source": [
    "### Endpoint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ceb1e-4746-43b7-8431-8c7d2c4d4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": variant_name,\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelDataDownloadTimeoutInSeconds\": 3600,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600,\n",
    "            \"ManagedInstanceScaling\": {\n",
    "                \"Status\": \"ENABLED\",\n",
    "                \"MinInstanceCount\": 1,\n",
    "                \"MaxInstanceCount\": 1,\n",
    "            },\n",
    "            \"RoutingConfig\": {\"RoutingStrategy\": \"LEAST_OUTSTANDING_REQUESTS\"},\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0facc-f63e-404a-9b5b-01cab0cfdf10",
   "metadata": {},
   "source": [
    "### SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9c6c2-1d09-4d37-be58-44d4378bc431",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8a4b1-e1e0-4820-9726-901e8f0843f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.wait_for_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae86c4-6a98-4ae0-8855-48fd65b9968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_model_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57f449b-19e1-4165-bbca-6df5a31058ee",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd19367-b08e-4ce6-80c0-74d762ecf9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configuration = {\n",
    "    \"Image\": inference_image,\n",
    "    'ModelDataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3Uri': f\"{uploaded_model_s3_uri}/\",\n",
    "                    'S3DataType': 'S3Prefix',\n",
    "                    'CompressionType': 'None',\n",
    "                }\n",
    "            },\n",
    "    \"Environment\": {\n",
    "        \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
    "        \"MESSAGES_API_ENABLED\": \"true\",\n",
    "        \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"8\",\n",
    "        \"OPTION_MODEL_LOADING_TIMEOUT\": \"1500\",\n",
    "        \"SERVING_FAIL_FAST\": \"true\",\n",
    "        \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "        \"OPTION_ASYNC_MODE\": \"true\",\n",
    "        \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "        \"OPTION_ENABLE_STREAMING\": \"true\",\n",
    "        \"HF_TOKEN\": hf_token,\n",
    "        \"MAX_TOTAL_TOKENS\": json.dumps(4096)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc661d9-f23a-413c-ad06-d79c2ba0e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    Containers=[model_configuration],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab66fb-5d79-42d0-b87f-edd24b601c90",
   "metadata": {},
   "source": [
    "### Inference Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d37c09-59dc-4371-90a2-4ed936eb9d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.create_inference_component(\n",
    "    InferenceComponentName=inference_component_name,\n",
    "    EndpointName=endpoint_name,\n",
    "    VariantName=variant_name,\n",
    "    Specification={\n",
    "        \"ModelName\": model_name,\n",
    "        \"ComputeResourceRequirements\": {\n",
    "            \"NumberOfAcceleratorDevicesRequired\": num_gpu,\n",
    "            \"NumberOfCpuCoresRequired\": 1,\n",
    "            \"MinMemoryRequiredInMb\": 1024,\n",
    "        },\n",
    "    },\n",
    "    RuntimeConfig={\"CopyCount\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623c364-d597-4dea-8f40-0b5ab2ad1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "while True:\n",
    "    desc = sm_client.describe_inference_component(\n",
    "        InferenceComponentName=inference_component_name\n",
    "    )\n",
    "    status = desc[\"InferenceComponentStatus\"]\n",
    "    print(status)\n",
    "    sys.stdout.flush()\n",
    "    if status in [\"InService\", \"Failed\"]:\n",
    "        break\n",
    "    time.sleep(30)\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal time taken: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d2a12-a4b4-4735-9483-3737cd670359",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410301d7-a11f-4292-8118-97237bcadce9",
   "metadata": {},
   "source": [
    "Invoke your running endpoint with boto3 invoke_endpoint or invoke_endpoint_with_response_stream runtime api calls. If you have an existing endpoint, you don't need to recreate the predictor and can follow below example to invoke the endpoint with an endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f9d16-ce71-499c-93c6-104251be4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b825fd-e525-4c3f-bf74-d119c8bd8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_runtime = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084bf7b-7739-487c-8872-b447a271d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = {\n",
    "    'messages':[\n",
    "    {\"role\": \"user\", \"content\": \"How many R are in STRAWBERRY? Keep your answer and explanation short!\"}\n",
    "],\n",
    "    'temperature':0.7,\n",
    "    'top_p':0.8,\n",
    "    'top_k':20,\n",
    "    'max_tokens':512,\n",
    "}\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    InferenceComponentName=inference_component_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ccba3-c2cf-48da-9bff-f8967bf09351",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "response_content = response_dict['choices'][0]['message']['content']\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f0df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
