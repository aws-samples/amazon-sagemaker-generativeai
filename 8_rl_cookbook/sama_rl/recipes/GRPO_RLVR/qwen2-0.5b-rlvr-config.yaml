model:
  name: "Qwen/Qwen2.5-0.5B"
  trust_remote_code: true
  hf_token: ""  # Set via parameter

data:
  dataset_name: "gsm8k"
  num_shots: 8
  test_size: 0.1
  max_samples: 1000  # Limit for faster training

training:
  learning_rate: 5e-7
  num_epochs: 1
  batch_size: 1
  eval_batch_size: 1
  gradient_accumulation_steps: 8
  max_steps: 100
  
  # RLVR specific
  reward_type: "verifiable"
  verification_steps: true
  mathematical_reasoning: true

algorithm:
  name: "grpo_rlvr"
  type: "reinforcement_learning"
  
reward:
  type: "mathematical_verification"
  base_reward: 0.5
  reasoning_bonus: 0.3
  operation_bonus: 0.2
  
wandb:
  project: "qwen2.5-grpo-rlvr"
  run_name: "qwen2.5-0.5b-gsm8k-rlvr"
  tags: ["qwen2.5", "grpo", "rlvr", "gsm8k", "0.5b"]

output:
  dir: "/opt/ml/model"
  save_total_limit: 3

sagemaker:
  instance_type: "ml.g5.2xlarge"  # 24GB GPU for RLVR
  instance_count: 1
  max_run: 7200  # 2 hours
  keep_alive_period: 1800
