model:
  name: "Qwen/Qwen2.5-0.5B-Instruct"
  trust_remote_code: true


data:
  dataset_name: "stanfordnlp/imdb"
  train_split: "train[:8000]"
  test_split: "test[:200]"
  input_min_length: 2
  input_max_length: 8

training:
  max_steps: 800
  learning_rate: 1.41e-5
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 2
  warmup_steps: 80
  weight_decay: 0.01
  
  # Qwen-optimized settings
  fp16: true
  gradient_checkpointing: true
  dataloader_num_workers: 2
  remove_unused_columns: false
  
  # Evaluation and logging
  eval_strategy: "steps"
  eval_steps: 100
  logging_steps: 20
  save_strategy: "steps"
  save_steps: 200
  do_eval: true

ppo:
  # PPO-specific parameters
  ppo_epochs: 4
  mini_batch_size: 1
  cliprange: 0.2
  cliprange_value: 0.2
  vf_coef: 0.1
  
  # Generation parameters
  max_new_tokens: 16
  min_new_tokens: 4
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  do_sample: true
  pad_token_id: 151643  # Qwen2.5 EOS token
  
  # KL penalty
  kl_penalty: "kl"
  target_kl: 0.1
  init_kl_coef: 0.2

wandb:
  project: "qwen2.5-ppo-experiments"
  run_name: "qwen2.5-0.5b-sentiment-ppo"
  tags: ["qwen2.5", "ppo", "sentiment", "0.5b"]
  
output:
  dir: "/opt/ml/model"
  save_total_limit: 3

sagemaker:
  instance_type: "ml.g4dn.4xlarge"
  instance_count: 1
  max_run: 3600
  keep_alive_period: 1800
