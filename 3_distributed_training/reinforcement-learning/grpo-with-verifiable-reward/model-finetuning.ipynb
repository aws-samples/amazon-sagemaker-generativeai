{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c81eda-20ae-46ac-b938-eadc49773f9a",
   "metadata": {},
   "source": [
    "## Fine tune model with GRPO verifiable reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d552a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:59:22.172489Z",
     "iopub.status.busy": "2025-10-01T19:59:22.172091Z",
     "iopub.status.idle": "2025-10-01T19:59:22.175291Z",
     "shell.execute_reply": "2025-10-01T19:59:22.174712Z",
     "shell.execute_reply.started": "2025-10-01T19:59:22.172472Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['hf_token']=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4754a610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:59:25.770145Z",
     "iopub.status.busy": "2025-10-01T19:59:25.769177Z",
     "iopub.status.idle": "2025-10-01T19:59:25.982959Z",
     "shell.execute_reply": "2025-10-01T19:59:25.982494Z",
     "shell.execute_reply.started": "2025-10-01T19:59:25.770093Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=os.environ[\"hf_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73a7e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:59:26.637585Z",
     "iopub.status.busy": "2025-10-01T19:59:26.636847Z",
     "iopub.status.idle": "2025-10-01T19:59:28.191108Z",
     "shell.execute_reply": "2025-10-01T19:59:28.190312Z",
     "shell.execute_reply.started": "2025-10-01T19:59:26.637548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036e995a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:59:29.772291Z",
     "iopub.status.busy": "2025-10-01T19:59:29.771683Z",
     "iopub.status.idle": "2025-10-01T19:59:31.395779Z",
     "shell.execute_reply": "2025-10-01T19:59:31.395298Z",
     "shell.execute_reply.started": "2025-10-01T19:59:29.772274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1226dac28f4933bd4c2b5eff2b87c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from scripts.utils.gsm8k import GSM8K\n",
    "# Get the dataset from Huggingface\n",
    "dataset = GSM8K(split='train', include_answer=False, include_reasoning=True, few_shot=True, num_shots=8, seed=None, cot=True).dataset.shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc23c287-71c3-471b-a851-3f13f0c1220b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:59:51.662678Z",
     "iopub.status.busy": "2025-10-01T19:59:51.662303Z",
     "iopub.status.idle": "2025-10-01T19:59:51.666760Z",
     "shell.execute_reply": "2025-10-01T19:59:51.666222Z",
     "shell.execute_reply.started": "2025-10-01T19:59:51.662662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'prompt', 'final_answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928c3f98-c34d-46d9-9bdd-872cf65aa30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:59:52.824764Z",
     "iopub.status.busy": "2025-10-01T19:59:52.824295Z",
     "iopub.status.idle": "2025-10-01T19:59:52.832784Z",
     "shell.execute_reply": "2025-10-01T19:59:52.832363Z",
     "shell.execute_reply.started": "2025-10-01T19:59:52.824749Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train_val = dataset.train_test_split(test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1342e2c1-5b39-4173-becf-7833499ed025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:59:53.320614Z",
     "iopub.status.busy": "2025-10-01T19:59:53.320028Z",
     "iopub.status.idle": "2025-10-01T19:59:53.323566Z",
     "shell.execute_reply": "2025-10-01T19:59:53.323190Z",
     "shell.execute_reply.started": "2025-10-01T19:59:53.320600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'prompt', 'final_answer'],\n",
       "        num_rows: 6725\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'prompt', 'final_answer'],\n",
       "        num_rows: 748\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1a4a3-d427-4130-b52e-c04c381f23fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9219986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5aacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028ee5c-4474-4d7e-98ff-28ae0cbe07dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "795b552e-961d-47ee-815e-502329a41969",
   "metadata": {},
   "source": [
    "Train the model using the Model Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd6ea40-8d2d-4ee7-8f99-16bdb0f273ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:59:56.292870Z",
     "iopub.status.busy": "2025-10-01T19:59:56.292487Z",
     "iopub.status.idle": "2025-10-01T19:59:57.348075Z",
     "shell.execute_reply": "2025-10-01T19:59:57.347530Z",
     "shell.execute_reply.started": "2025-10-01T19:59:56.292855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6546e3203e1748d3b7580c6c583db30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9201b44a62b840d58c2ada76ba45af63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to:\n",
      "s3://sagemaker-us-east-1-783764584149/datasets/finetuning-modeltrainer-rlvr/train/dataset.json\n",
      "s3://sagemaker-us-east-1-783764584149/datasets/finetuning-modeltrainer-rlvr/val/dataset.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import shutil\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "\n",
    "# save train_dataset to s3 using our SageMaker session\n",
    "if default_prefix:\n",
    "    input_path = f\"{default_prefix}/datasets/finetuning-modeltrainer-rlvr\"\n",
    "else:\n",
    "    input_path = f\"datasets/finetuning-modeltrainer-rlvr\"\n",
    "\n",
    "train_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/train/dataset.json\"\n",
    "val_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/val/dataset.json\"\n",
    "\n",
    "# Save datasets to s3\n",
    "# We will fine tune only with 20 records due to limited compute resource for the workshop\n",
    "dataset_train_val['train'].to_json(\"./data/train/dataset.json\", orient=\"records\")\n",
    "dataset_train_val['test'].to_json(\"./data/val/dataset.json\", orient=\"records\")\n",
    "\n",
    "s3_client.upload_file(\"./data/train/dataset.json\", bucket_name, f\"{input_path}/train/dataset.json\")\n",
    "s3_client.upload_file(\"./data/val/dataset.json\", bucket_name, f\"{input_path}/val/dataset.json\")\n",
    "\n",
    "shutil.rmtree(\"./data\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(val_dataset_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13a614f-99c3-4fa6-971a-d14d746b1191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:46.084682Z",
     "iopub.status.busy": "2025-10-01T20:00:46.084319Z",
     "iopub.status.idle": "2025-10-01T20:00:46.087710Z",
     "shell.execute_reply": "2025-10-01T20:00:46.087306Z",
     "shell.execute_reply.started": "2025-10-01T20:00:46.084666Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_SERVER_ARN = \"\" # or \"arn:aws:sagemaker:us-west-2:<account-id>:mlflow-tracking-server/<server-name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8511b006-b935-42e3-9b7d-02240f2129b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:58.208082Z",
     "iopub.status.busy": "2025-10-01T20:00:58.207655Z",
     "iopub.status.idle": "2025-10-01T20:00:58.482457Z",
     "shell.execute_reply": "2025-10-01T20:00:58.481502Z",
     "shell.execute_reply.started": "2025-10-01T20:00:58.208067Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml.g6.48xlarge\n",
      "Qwen2.5-0.5B.yaml\n",
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.7.1-gpu-py312\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.config import load_sagemaker_config\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "configs = load_sagemaker_config()\n",
    "instance_type = \"ml.g6.48xlarge\" # Override the instance type if you want to get a different container version\n",
    "instance_count = 1\n",
    "config_filename = \"Qwen2.5-0.5B.yaml\" \n",
    "print(instance_type)\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"2.7.1\",\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"training\"\n",
    ")\n",
    "print(config_filename)\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3f37055-f9b0-44a5-b195-0a7e35af022a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:01:03.503499Z",
     "iopub.status.busy": "2025-10-01T20:01:03.502739Z",
     "iopub.status.idle": "2025-10-01T20:01:03.918012Z",
     "shell.execute_reply": "2025-10-01T20:01:03.917588Z",
     "shell.execute_reply.started": "2025-10-01T20:01:03.503460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-Qwen2-5-0-5B-rlvr\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/01/25 20:01:03] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> SageMaker session not provided. Using default Session.            <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#501\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/01/25 20:01:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m SageMaker session not provided. Using default Session.            \u001b]8;id=906435;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=816129;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#501\u001b\\\u001b[2m501\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Role not provided. Using default role:                            <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#505\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">505</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         arn:aws:iam::<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">783764584149</span>:role/service-role/AmazonSageMaker-Execu <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         tionRole-20241230T144802                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Role not provided. Using default role:                            \u001b]8;id=508510;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=680996;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#505\u001b\\\u001b[2m505\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         arn:aws:iam::\u001b[1;36m783764584149\u001b[0m:role/service-role/AmazonSageMaker-Execu \u001b[2m                    \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         tionRole-20241230T144802                                          \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> OutputDataConfig compression type not provided. Using default:    <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#582\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">582</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         GZIP                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m OutputDataConfig compression type not provided. Using default:    \u001b]8;id=227539;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=991163;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#582\u001b\\\u001b[2m582\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         GZIP                                                              \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Training image URI:                                               <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#588\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">588</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">763104351884.</span>dkr.ecr.us-east-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>amazonaws.com/pytorch-training:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.7</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         .<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-gpu-py312                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Training image URI:                                               \u001b]8;id=119188;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149828;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#588\u001b\\\u001b[2m588\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m763104351884.\u001b[0mdkr.ecr.us-east-\u001b[1;36m1.\u001b[0mamazonaws.com/pytorch-training:\u001b[1;36m2.7\u001b[0m \u001b[2m                    \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         .\u001b[1;36m1\u001b[0m-gpu-py312                                                      \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.modules.configs import (\n",
    "    CheckpointConfig,\n",
    "    Compute,\n",
    "    OutputDataConfig,\n",
    "    SourceCode,\n",
    "    StoppingCondition,\n",
    ")\n",
    "from sagemaker.modules.distributed import Torchrun\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "env = {}\n",
    "env[\"FI_PROVIDER\"] = \"efa\"\n",
    "env[\"NCCL_PROTO\"] = \"simple\"\n",
    "env[\"NCCL_SOCKET_IFNAME\"] = \"eth0\"\n",
    "env[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "env[\"NCCL_DEBUG\"] = \"WARN\"\n",
    "env[\"HF_token\"] = os.environ['hf_token']\n",
    "env[\"CONFIG_PATH\"] = f\"recipes/{config_filename}\"\n",
    "env[\"MLFLOW_EXPERIMENT_NAME\"]= \"grpo-rlvr\"\n",
    "env[\"MLFLOW_TAGS\"] =  '{\"source.job\": \"sm-training-jobs\", \"source.type\": \"grpo-rlvr\", \"source.framework\": \"pytorch\"}'\n",
    "env[\"MLFLOW_TRACKING_URI\"] =  MLFLOW_TRACKING_SERVER_ARN\n",
    "# Define the script to be run\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"./scripts\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    entry_script=\"run_finetuning.sh\",\n",
    ")\n",
    "\n",
    "# Define the compute\n",
    "compute_configs = Compute(\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    keep_alive_period_in_seconds=3600,\n",
    ")\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f\"train-{config_filename.split('/')[-1].replace('.', '-').replace('yaml', 'rlvr')}\"\n",
    "print(job_name)\n",
    "# define OutputDataConfig path\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{job_name}\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{job_name}\"\n",
    "\n",
    "# Define the ModelTrainer\n",
    "model_trainer = ModelTrainer(\n",
    "    training_image=image_uri,\n",
    "     environment=env,\n",
    "    source_code=source_code,\n",
    "    base_job_name=job_name,\n",
    "    compute=compute_configs,\n",
    "    stopping_condition=StoppingCondition(max_runtime_in_seconds=18000),\n",
    "    output_data_config=OutputDataConfig(s3_output_path=output_path),\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        s3_uri=output_path + \"/checkpoint\", local_path=\"/opt/ml/checkpoints\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d54fb4-50fe-4881-9ac9-01bc4bd5188c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:01:05.063052Z",
     "iopub.status.busy": "2025-10-01T20:01:05.062340Z",
     "iopub.status.idle": "2025-10-01T20:01:05.066683Z",
     "shell.execute_reply": "2025-10-01T20:01:05.066300Z",
     "shell.execute_reply.started": "2025-10-01T20:01:05.063017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InputData(channel_name='train', data_source='s3://sagemaker-us-east-1-783764584149/datasets/finetuning-modeltrainer-rlvr/train/dataset.json'),\n",
       " InputData(channel_name='val', data_source='s3://sagemaker-us-east-1-783764584149/datasets/finetuning-modeltrainer-rlvr/val/dataset.json')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.modules.configs import InputData\n",
    "\n",
    "# Pass the input data\n",
    "train_input = InputData(\n",
    "    channel_name=\"train\",\n",
    "    data_source=train_dataset_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "val_input = InputData(\n",
    "    channel_name=\"val\",\n",
    "    data_source=val_dataset_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "# Check input channels configured\n",
    "data = [train_input, val_input]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea2a2d5a-3084-46f0-934e-6e479d3807ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:50:24.903440Z",
     "iopub.status.busy": "2025-10-01T23:50:24.903296Z",
     "iopub.status.idle": "2025-10-01T23:50:24.905781Z",
     "shell.execute_reply": "2025-10-01T23:50:24.905293Z",
     "shell.execute_reply.started": "2025-10-01T23:50:24.903425Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_trainer.train(input_data_config=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d131456-2c73-4ac7-aa86-a86a889402e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Load Fine-Tuned model\n",
    "\n",
    "Note: Run `train_fn` with `merge_weights=True` for merging the trained adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a2d8f-eff0-4b2b-968c-5fea8f8a96fa",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35481eff-1142-46f3-8e38-50a1bdadba7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T13:45:11.757861Z",
     "start_time": "2023-09-03T13:45:11.747993Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:10.758587Z",
     "iopub.status.busy": "2025-10-01T23:31:10.758452Z",
     "iopub.status.idle": "2025-10-01T23:31:11.146231Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "job_prefix = f\"train-{config_filename.split('/')[-1].replace('.', '-').replace('yaml', 'rlvr')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed118e7-1c80-4392-8ea5-147b63fc2f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:11.148591Z",
     "iopub.status.busy": "2025-10-01T23:31:11.148383Z",
     "iopub.status.idle": "2025-10-01T23:31:11.152402Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "    matching_jobs = []\n",
    "    next_token = None\n",
    "\n",
    "    while True:\n",
    "        # Prepare the search parameters\n",
    "        search_params = {\n",
    "            'Resource': 'TrainingJob',\n",
    "            'SearchExpression': {\n",
    "                'Filters': [\n",
    "                    {\n",
    "                        'Name': 'TrainingJobName',\n",
    "                        'Operator': 'Contains',\n",
    "                        'Value': job_name_prefix\n",
    "                    },\n",
    "                    {\n",
    "                        'Name': 'TrainingJobStatus',\n",
    "                        'Operator': 'Equals',\n",
    "                        'Value': \"Completed\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            'SortBy': 'CreationTime',\n",
    "            'SortOrder': 'Descending',\n",
    "            'MaxResults': 100\n",
    "        }\n",
    "\n",
    "        # Add NextToken if we have one\n",
    "        if next_token:\n",
    "            search_params['NextToken'] = next_token\n",
    "\n",
    "        # Make the search request\n",
    "        search_response = sagemaker_client.search(**search_params)\n",
    "\n",
    "        # Filter and add matching jobs\n",
    "        matching_jobs.extend([\n",
    "            job['TrainingJob']['TrainingJobName'] \n",
    "            for job in search_response['Results']\n",
    "            if job['TrainingJob']['TrainingJobName'].startswith(job_name_prefix)\n",
    "        ])\n",
    "\n",
    "        # Check if we have more results to fetch\n",
    "        next_token = search_response.get('NextToken')\n",
    "        if not next_token or matching_jobs:  # Stop if we found at least one match or no more results\n",
    "            break\n",
    "\n",
    "    if not matching_jobs:\n",
    "        raise ValueError(f\"No completed training jobs found starting with prefix '{job_name_prefix}'\")\n",
    "\n",
    "    return matching_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4e9bd-de61-4806-b314-6bcf988a2c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:11.158072Z",
     "iopub.status.busy": "2025-10-01T23:31:11.157596Z",
     "iopub.status.idle": "2025-10-01T23:31:12.238053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train-Qwen2-5-0-5B-rlvr', 'train-Qwen2-5-0-5B-rlvr-20251001200106')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_prefix, job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117530f-c55d-452f-8c10-63046149e2cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Inference configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf469f4-c71e-4cbb-9b45-3a6ad1e66e97",
   "metadata": {},
   "source": [
    "## Download model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff4d15-27cd-4def-b220-5925393a2fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:12.240294Z",
     "iopub.status.busy": "2025-10-01T23:31:12.240154Z",
     "iopub.status.idle": "2025-10-01T23:31:16.000815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded train-Qwen2-5-0-5B-rlvr/train-Qwen2-5-0-5B-rlvr-20251001200106/output/model.tar.gz to ./temp/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "if default_prefix:\n",
    "    object_key = f\"{default_prefix}/{job_prefix}/{job_name}/output/model.tar.gz\"\n",
    "else:\n",
    "    object_key = f\"{job_prefix}/{job_name}/output/model.tar.gz\"\n",
    "\n",
    "\n",
    "\n",
    "# Local paths\n",
    "local_archive_path = './temp/model.tar.gz'\n",
    "local_model_dir = './temp/extracted_model'\n",
    "\n",
    "# Create the /tmp directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(local_archive_path), exist_ok=True)\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "# Download the file from S3\n",
    "s3_client.download_file(bucket_name, object_key, local_archive_path)\n",
    "\n",
    "print(f\"Downloaded {object_key} to {local_archive_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec609ac7-d3f1-469f-baf9-db26c62e9af0",
   "metadata": {},
   "source": [
    "### Extract The model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6758b-5646-4179-92a5-99127bc4bc07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:16.001478Z",
     "iopub.status.busy": "2025-10-01T23:31:16.001322Z",
     "iopub.status.idle": "2025-10-01T23:31:25.589742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27964/3173588015.py:5: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=local_model_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted model files to ./temp/extracted_model\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# Extract the tar.gz file\n",
    "with tarfile.open(local_archive_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=local_model_dir)\n",
    "\n",
    "print(f\"Extracted model files to {local_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28824be-cb60-421e-8488-a4825cf5697d",
   "metadata": {},
   "source": [
    "### Evaluate The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8d3f2-59c0-4972-b129-8247f65b6f61",
   "metadata": {},
   "source": [
    "At first we need to merge the adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fae9aa-6bb9-4bc7-abeb-55c62abff336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:25.590407Z",
     "iopub.status.busy": "2025-10-01T23:31:25.590229Z",
     "iopub.status.idle": "2025-10-01T23:31:33.097784Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 23:31:29.220171: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759361489.231729   27964 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759361489.235359   27964 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-01 23:31:29.247113: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-01 23:31:31,037] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/../lib/gcc/x86_64-conda-linux-gnu/13.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/opt/conda/bin/../lib/gcc/x86_64-conda-linux-gnu/13.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "from dataclasses import dataclass, field\n",
    "import tempfile\n",
    "from typing import Optional\n",
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from peft import PeftConfig, PeftModel, AutoPeftModelForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770a7da-9bd5-4cb4-acab-696fe2240441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:33.098795Z",
     "iopub.status.busy": "2025-10-01T23:31:33.098356Z",
     "iopub.status.idle": "2025-10-01T23:31:33.747715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a98648063644d69131e88e2a7c2fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Load the dataset, tokenizer, and model ---\n",
    "# Use the GSM8K test split.\n",
    "dataset = GSM8K(split='test', include_answer=False, include_reasoning=True, few_shot=True, num_shots=8, seed=None, cot=True).dataset.shuffle(seed=42)\n",
    "\n",
    "dataset = dataset.select(range(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471206a-f9d2-4eee-9bdc-0946ba11861a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:33.748393Z",
     "iopub.status.busy": "2025-10-01T23:31:33.748240Z",
     "iopub.status.idle": "2025-10-01T23:31:33.753187Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_and_save_model(model_path_or_id, save_dir, save_tokenizer=True):\n",
    "    # Load the base model and tokenizer\n",
    "    config = PeftConfig.from_pretrained(model_path_or_id)\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path_or_id)\n",
    "    \n",
    "    # Add special tokens to the tokenizer\n",
    "    #tokenizer.add_special_tokens({'pad_token': ''})\n",
    "    \n",
    "    # Resize the token embeddings of the base model\n",
    "    base_model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    # Now load the PEFT model with the resized base model\n",
    "    model = PeftModel.from_pretrained(base_model, model_path_or_id)\n",
    "    \n",
    "    # Merge LoRA and base model and save\n",
    "    model = model.merge_and_unload()        \n",
    "    model.save_pretrained(save_dir, safe_serialization=True, max_shard_size=\"3GB\")\n",
    "  \n",
    "    # save tokenizer\n",
    "    if save_tokenizer:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path_or_id)\n",
    "        tokenizer.save_pretrained(save_dir) \n",
    "        \n",
    "def extract_answer(text):\n",
    "    \"\"\"\n",
    "    Extracts the numerical answer from the model's text output.\n",
    "    This function looks for the final number in the output, which is a common practice.\n",
    "    It removes commas to handle large numbers correctly.\n",
    "    \"\"\"\n",
    "    # The `re.findall` finds all sequences of digits, potentially with a minus sign.\n",
    "    numbers = re.findall(r'-?\\d+', text.replace(',', ''))\n",
    "    if numbers:\n",
    "        # We assume the final number is the answer.\n",
    "        return numbers[-1]\n",
    "    return None\n",
    "# Run the evaluation \n",
    "# For a full evaluation, you would generate a CoT prompt with examples from the train set.\n",
    "# For simplicity, this example uses a zero-shot prompt.\n",
    "# Few-shot CoT prompting is the standard approach for best results.\n",
    "def evaluate_on_gsm8k():\n",
    "    correct_count = 0\n",
    "    total_count = len(dataset)\n",
    "\n",
    "\n",
    "    for i, example in enumerate(dataset):\n",
    "        question = example[\"question\"]\n",
    "        ground_truth = example[\"final_answer\"]\n",
    "\n",
    "        # Create a simple prompt. For CoT, you would construct a more complex prompt.\n",
    "        prompt = example[\"prompt\"]\n",
    "\n",
    "        # Generate the model's response.\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "        model_output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract the model's predicted answer.\n",
    "        predicted_answer = extract_answer(model_output_text)\n",
    "\n",
    "        # print(f\"--- Example {i+1}/{total_count} ---\")\n",
    "        # print(f\"Question: {question}\")\n",
    "        # print(f\"Model Output: {model_output_text}\")\n",
    "        # print(f\"Extracted Answer: {predicted_answer}\")\n",
    "        # print(f\"Ground Truth: {ground_truth}\")\n",
    "        # print(f\"--------------------------------\")\n",
    "\n",
    "        if predicted_answer and predicted_answer == ground_truth:\n",
    "            correct_count += 1\n",
    "            #print(\"Status: Correct\\n\")\n",
    "        else:\n",
    "            correct_count=correct_count\n",
    "            #print(\"Status: Incorrect\\n\")\n",
    "\n",
    "    accuracy = correct_count / total_count\n",
    "    print(\"--- Evaluation Summary ---\")\n",
    "    print(f\"Total problems: {total_count}\")\n",
    "    print(f\"Correct predictions: {correct_count}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5db1a7-e8da-4616-b9a4-ad5805883703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:33.753756Z",
     "iopub.status.busy": "2025-10-01T23:31:33.753618Z",
     "iopub.status.idle": "2025-10-01T23:31:39.138796Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "merge_and_save_model('./temp/extracted_model/Qwen2.5-0.5B-RL-VR-GRPO', './temp/merged-weights/Qwen2.5-0.5B-RL-VR-GRPO', save_tokenizer=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afc4dd-710a-471f-9217-fa4b9101f420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:39.143287Z",
     "iopub.status.busy": "2025-10-01T23:31:39.143123Z",
     "iopub.status.idle": "2025-10-01T23:31:39.502557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained model and tokenizer\n",
    "#model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "model_name = \"./temp/merged-weights/Qwen2.5-0.5B-RL-VR-GRPO\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb899924-8053-4083-b715-817d52a69cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:31:39.503279Z",
     "iopub.status.busy": "2025-10-01T23:31:39.503116Z",
     "iopub.status.idle": "2025-10-01T23:40:44.485350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Summary ---\n",
      "Total problems: 50\n",
      "Correct predictions: 22\n",
      "Accuracy: 0.4400\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_gsm8k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d7f0e-695b-4ff8-a29b-5c3a20c3af32",
   "metadata": {},
   "source": [
    "### Run evaluation on base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bff3ae-40ac-4bf3-8bef-08d4793d5282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:40:44.486260Z",
     "iopub.status.busy": "2025-10-01T23:40:44.486088Z",
     "iopub.status.idle": "2025-10-01T23:40:45.048479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained model and tokenizer from Hugging Face Hub.\n",
    "# You can replace this with your own model.\n",
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8aabc5-71ad-46b6-887b-e3fbd830d831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T23:40:45.049495Z",
     "iopub.status.busy": "2025-10-01T23:40:45.049333Z",
     "iopub.status.idle": "2025-10-01T23:50:24.891021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Summary ---\n",
      "Total problems: 50\n",
      "Correct predictions: 12\n",
      "Accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_gsm8k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2f46e-3dcc-4ea4-8822-d1485bda0ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
