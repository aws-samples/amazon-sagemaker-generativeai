{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c81eda-20ae-46ac-b938-eadc49773f9a",
   "metadata": {},
   "source": [
    "## Fine tune model with GRPO verifiable reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d552a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['hf_token']=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4754a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=os.environ[\"hf_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73a7e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036e995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c6e0f458864f62bb40a1428ad1dbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map: 100%|##########| 7473/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from scripts.utils.gsm8k import GSM8K\n",
    "# Get the dataset from Huggingface\n",
    "Num_shots = 8\n",
    "dataset = GSM8K(split='train', include_answer=False, include_reasoning=True, few_shot=True, num_shots=Num_shots, seed=42, cot=True).dataset.shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc23c287-71c3-471b-a851-3f13f0c1220b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'prompt', 'final_answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928c3f98-c34d-46d9-9bdd-872cf65aa30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_val = dataset.train_test_split(test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1342e2c1-5b39-4173-becf-7833499ed025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'prompt', 'final_answer'],\n",
       "        num_rows: 6725\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'prompt', 'final_answer'],\n",
       "        num_rows: 748\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad1a4a3-d427-4130-b52e-c04c381f23fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question: A farmer has a total of 80 apples and oranges. If he has 30 apples, how many oranges does he have?\\nSolution: Let's think step by step. To determine the number of oranges, we subtract the number of apples from the total number of fruits. So, the number of oranges is 80 - 30 = 50.\\n#### The final answer is 50\\n\\nQuestion: Emily has 3 times as many pencils as Alice. If Alice has 15 pencils, how many pencils does Emily have?\\nSolution: Let's think step by step. To find out how many pencils Emily has, we multiply the number of pencils Alice has by 3. Alice has 15 pencils, so Emily has 15 * 3 = 45 pencils.\\n#### The final answer is 45\\n\\nQuestion: Samantha baked 40 cookies and wants to divide them equally into bags, with each bag containing 5 cookies. How many bags will Samantha need?\\nSolution: Let's think step by step. To find the number of bags needed, divide the total number of cookies by the number of cookies per bag. Thus, 40 divided by 5 equals 8.\\n#### The final answer is 8\\n\\nQuestion: Jack has collected 12 more marbles than Kevin. If Kevin has 27 marbles, how many marbles does Jack have?\\nSolution: Let's think step by step. To find how many marbles Jack has, we add 12 to the number of marbles Kevin has. So, Jack has 27 + 12 = 39 marbles.\\n#### The final answer is 39\\n\\nQuestion: Mark has $50 and buys a toy that costs $35. How much money does he have left?\\nSolution: Let's think step by step. To find out how much money Mark has left, subtract the cost of the toy from the total amount of money Mark has. So, $50 - $35 = $15.\\n#### The final answer is 15\\n\\nQuestion: There are 24 students in a classroom. If each group must have 4 students, how many groups can be formed?\\nSolution: Let's think step by step. To find how many groups can be formed, we divide the number of students by the number of students per group. So, 24 / 4 = 6 groups can be formed.\\n#### The final answer is 6\\n\\nQuestion: A pack of pencils costs $4. If you buy 7 packs, how much will you spend in total?\\nSolution: Let's think step by step. The total cost is found by multiplying the cost per pack by the number of packs. Hence, you spend 7 * $4 = $28.\\n#### The final answer is 28\\n\\nQuestion: A book has 240 pages, and Sarah reads 20 pages each day. How many days will it take her to finish the book?\\nSolution: Let's think step by step. Sarah reads 20 pages per day, so we divide the total pages by the number of pages she reads per day. Therefore, it takes her 240 / 20 = 12 days to finish the book.\\n#### The final answer is 12\\n\\nQuestion: Olaf collects colorful toy cars. At first, his collection consisted of 150 cars. His family, knowing his hobby, decided to give him some toy cars. Grandpa gave Olaf twice as many toy cars as the uncle. Dad gave Olaf 10 toy cars, 5 less than Mum. Auntie gave Olaf 6 toy cars, 1 more than the uncle. How many toy cars does Olaf have in total, after receiving all these gifts?\\nSolution: Let's think step by step. \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['prompt'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9219986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5aacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028ee5c-4474-4d7e-98ff-28ae0cbe07dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "795b552e-961d-47ee-815e-502329a41969",
   "metadata": {},
   "source": [
    "Train the model using the Model Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd6ea40-8d2d-4ee7-8f99-16bdb0f273ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb48d5effd84992863d3c57c69159ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f05899d4884b479b6f8cd3f73c1611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to:\n",
      "s3://sagemaker-us-east-1-783764584149/datasets/finetuning-modeltrainer-rlvr/train/dataset.json\n",
      "s3://sagemaker-us-east-1-783764584149/datasets/finetuning-modeltrainer-rlvr/val/dataset.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import shutil\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "\n",
    "# save train_dataset to s3 using our SageMaker session\n",
    "if default_prefix:\n",
    "    input_path = f\"{default_prefix}/datasets/finetuning-modeltrainer-rlvr\"\n",
    "else:\n",
    "    input_path = f\"datasets/finetuning-modeltrainer-rlvr\"\n",
    "\n",
    "train_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/train/dataset.json\"\n",
    "val_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/val/dataset.json\"\n",
    "\n",
    "# Save datasets to s3\n",
    "# We will fine tune only with 20 records due to limited compute resource for the workshop\n",
    "dataset_train_val['train'].to_json(\"./data/train/dataset.json\", orient=\"records\")\n",
    "dataset_train_val['test'].to_json(\"./data/val/dataset.json\", orient=\"records\")\n",
    "\n",
    "s3_client.upload_file(\"./data/train/dataset.json\", bucket_name, f\"{input_path}/train/dataset.json\")\n",
    "s3_client.upload_file(\"./data/val/dataset.json\", bucket_name, f\"{input_path}/val/dataset.json\")\n",
    "\n",
    "shutil.rmtree(\"./data\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(val_dataset_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13a614f-99c3-4fa6-971a-d14d746b1191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_SERVER_ARN = 'arn:aws:sagemaker:us-east-1:783764584149:mlflow-tracking-server/MLflow3-test' # or \"arn:aws:sagemaker:us-west-2:<account-id>:mlflow-tracking-server/<server-name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8511b006-b935-42e3-9b7d-02240f2129b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml.p4d.24xlarge\n",
      "Qwen2.5-0.5B.yaml\n",
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.7.1-gpu-py312\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.config import load_sagemaker_config\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "configs = load_sagemaker_config()\n",
    "instance_type = \"ml.p4d.24xlarge\" #\"ml.g6.48xlarge\" # Override the instance type if you want to get a different container version\n",
    "instance_count = 1\n",
    "config_filename = \"Qwen2.5-0.5B.yaml\" \n",
    "print(instance_type)\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"2.7.1\",\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"training\"\n",
    ")\n",
    "print(config_filename)\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3f37055-f9b0-44a5-b195-0a7e35af022a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-Qwen2-5-0-5B-rlvr-shots-8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/17/25 20:58:17] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> SageMaker session not provided. Using default Session.            <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#501\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/17/25 20:58:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m SageMaker session not provided. Using default Session.            \u001b]8;id=442417;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#501\u001b\\\u001b[2m501\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Role not provided. Using default role:                            <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#505\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">505</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         arn:aws:iam::<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">783764584149</span>:role/service-role/AmazonSageMaker-Execu <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         tionRole-20241230T144802                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Role not provided. Using default role:                            \u001b]8;id=631262;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=27824;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#505\u001b\\\u001b[2m505\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         arn:aws:iam::\u001b[1;36m783764584149\u001b[0m:role/service-role/AmazonSageMaker-Execu \u001b[2m                    \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         tionRole-20241230T144802                                          \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> OutputDataConfig compression type not provided. Using default:    <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#582\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">582</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         GZIP                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m OutputDataConfig compression type not provided. Using default:    \u001b]8;id=571412;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=439898;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#582\u001b\\\u001b[2m582\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         GZIP                                                              \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Training image URI:                                               <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#588\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">588</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">763104351884.</span>dkr.ecr.us-east-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>amazonaws.com/pytorch-training:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.7</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         .<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>-gpu-py312                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Training image URI:                                               \u001b]8;id=911527;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=6814;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#588\u001b\\\u001b[2m588\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m763104351884.\u001b[0mdkr.ecr.us-east-\u001b[1;36m1.\u001b[0mamazonaws.com/pytorch-training:\u001b[1;36m2.7\u001b[0m \u001b[2m                    \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         .\u001b[1;36m1\u001b[0m-gpu-py312                                                      \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.modules.configs import (\n",
    "    CheckpointConfig,\n",
    "    Compute,\n",
    "    OutputDataConfig,\n",
    "    SourceCode,\n",
    "    StoppingCondition,\n",
    ")\n",
    "from sagemaker.modules.distributed import Torchrun\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "env = {}\n",
    "env[\"FI_PROVIDER\"] = \"efa\"\n",
    "env[\"NCCL_PROTO\"] = \"simple\"\n",
    "env[\"NCCL_SOCKET_IFNAME\"] = \"eth0\"\n",
    "env[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "env[\"NCCL_DEBUG\"] = \"WARN\"\n",
    "env[\"HF_token\"] = os.environ['hf_token']\n",
    "env[\"CONFIG_PATH\"] = f\"recipes/{config_filename}\"\n",
    "env[\"MLFLOW_EXPERIMENT_NAME\"]= \"grpo-rlvr\"\n",
    "env[\"MLFLOW_TAGS\"] =  '{\"source.job\": \"sm-training-jobs\", \"source.type\": \"grpo-rlvr\", \"source.framework\": \"pytorch\"}'\n",
    "env[\"MLFLOW_TRACKING_URI\"] =  MLFLOW_TRACKING_SERVER_ARN\n",
    "# Define the script to be run\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"./scripts\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    entry_script=\"run_finetuning.sh\",\n",
    ")\n",
    "\n",
    "# Define the compute\n",
    "compute_configs = Compute(\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    keep_alive_period_in_seconds=3600,\n",
    ")\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f\"train-{config_filename.split('/')[-1].replace('.', '-').replace('yaml', 'rlvr')}-shots-{Num_shots}\"\n",
    "print(job_name)\n",
    "# define OutputDataConfig path\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{job_name}\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{job_name}\"\n",
    "\n",
    "# Define the ModelTrainer\n",
    "model_trainer = ModelTrainer(\n",
    "    training_image=image_uri,\n",
    "     environment=env,\n",
    "    source_code=source_code,\n",
    "    base_job_name=job_name,\n",
    "    compute=compute_configs,\n",
    "    stopping_condition=StoppingCondition(max_runtime_in_seconds=18000),\n",
    "    output_data_config=OutputDataConfig(s3_output_path=output_path),\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        s3_uri=output_path + \"/checkpoint\", local_path=\"/opt/ml/checkpoints\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d54fb4-50fe-4881-9ac9-01bc4bd5188c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InputData(channel_name='train', data_source='s3://sagemaker-us-east-1-783764584149/datasets/finetuning-modeltrainer-rlvr/train/dataset.json'),\n",
       " InputData(channel_name='val', data_source='s3://sagemaker-us-east-1-783764584149/datasets/finetuning-modeltrainer-rlvr/val/dataset.json')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.modules.configs import InputData\n",
    "\n",
    "# Pass the input data\n",
    "train_input = InputData(\n",
    "    channel_name=\"train\",\n",
    "    data_source=train_dataset_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "val_input = InputData(\n",
    "    channel_name=\"val\",\n",
    "    data_source=val_dataset_s3_path, # S3 path where training data is stored\n",
    ")\n",
    "\n",
    "# Check input channels configured\n",
    "data = [train_input, val_input]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea2a2d5a-3084-46f0-934e-6e479d3807ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/17/25 20:58:19] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> key_prefix is only applicable when data_source is a local file    <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#896\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">896</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         path.                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/17/25 20:58:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m key_prefix is only applicable when data_source is a local file    \u001b]8;id=356778;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=291369;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#896\u001b\\\u001b[2m896\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         path.                                                             \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> key_prefix is only applicable when data_source is a local file    <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#896\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">896</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         path.                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m key_prefix is only applicable when data_source is a local file    \u001b]8;id=107175;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=97251;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#896\u001b\\\u001b[2m896\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         path.                                                             \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/17/25 20:58:20] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training_job resource.                                     <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/resources.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">resources.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/resources.py#28522\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28522</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/17/25 20:58:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training_job resource.                                     \u001b]8;id=277370;file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/resources.py\u001b\\\u001b[2mresources.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=846335;file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/resources.py#28522\u001b\\\u001b[2m28522\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10/17/25 20:58:20] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No region provided. Using default region.                                 <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/utils.py#343\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[10/17/25 20:58:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No region provided. Using default region.                                 \u001b]8;id=396922;file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=82627;file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/utils.py#343\u001b\\\u001b[2m343\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> No config provided. Using default config.                                 <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/utils.py#347\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">347</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m No config provided. Using default config.                                 \u001b]8;id=928463;file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=903565;file:///opt/conda/lib/python3.12/site-packages/sagemaker_core/main/utils.py#347\u001b\\\u001b[2m347\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Not displaing the training container logs as <span style=\"color: #008700; text-decoration-color: #008700\">'wait'</span> is set to     <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#834\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">834</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #d70000; text-decoration-color: #d70000; font-style: italic\">False</span>.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Not displaing the training container logs as \u001b[38;2;0;135;0m'wait'\u001b[0m is set to     \u001b]8;id=48050;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py\u001b\\\u001b[2mmodel_trainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=693384;file:///opt/conda/lib/python3.12/site-packages/sagemaker/modules/train/model_trainer.py#834\u001b\\\u001b[2m834\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[3;38;2;215;0;0mFalse\u001b[0m.                                                            \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_trainer.train(input_data_config=data, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d131456-2c73-4ac7-aa86-a86a889402e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Load Fine-Tuned model\n",
    "\n",
    "Note: Run `train_fn` with `merge_weights=True` for merging the trained adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a2d8f-eff0-4b2b-968c-5fea8f8a96fa",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35481eff-1142-46f3-8e38-50a1bdadba7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T13:45:11.757861Z",
     "start_time": "2023-09-03T13:45:11.747993Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "# define Training Job Name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "Num_shots = 8\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "job_prefix = f\"train-{config_filename.split('/')[-1].replace('.', '-').replace('yaml', 'rlvr')}-shots-{Num_shots}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ed118e7-1c80-4392-8ea5-147b63fc2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "    matching_jobs = []\n",
    "    next_token = None\n",
    "\n",
    "    while True:\n",
    "        # Prepare the search parameters\n",
    "        search_params = {\n",
    "            'Resource': 'TrainingJob',\n",
    "            'SearchExpression': {\n",
    "                'Filters': [\n",
    "                    {\n",
    "                        'Name': 'TrainingJobName',\n",
    "                        'Operator': 'Contains',\n",
    "                        'Value': job_name_prefix\n",
    "                    },\n",
    "                    {\n",
    "                        'Name': 'TrainingJobStatus',\n",
    "                        'Operator': 'Equals',\n",
    "                        'Value': \"Completed\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            'SortBy': 'CreationTime',\n",
    "            'SortOrder': 'Descending',\n",
    "            'MaxResults': 100\n",
    "        }\n",
    "\n",
    "        # Add NextToken if we have one\n",
    "        if next_token:\n",
    "            search_params['NextToken'] = next_token\n",
    "\n",
    "        # Make the search request\n",
    "        search_response = sagemaker_client.search(**search_params)\n",
    "\n",
    "        # Filter and add matching jobs\n",
    "        matching_jobs.extend([\n",
    "            job['TrainingJob']['TrainingJobName'] \n",
    "            for job in search_response['Results']\n",
    "            if job['TrainingJob']['TrainingJobName'].startswith(job_name_prefix)\n",
    "        ])\n",
    "\n",
    "        # Check if we have more results to fetch\n",
    "        next_token = search_response.get('NextToken')\n",
    "        if not next_token or matching_jobs:  # Stop if we found at least one match or no more results\n",
    "            break\n",
    "\n",
    "    if not matching_jobs:\n",
    "        raise ValueError(f\"No completed training jobs found starting with prefix '{job_name_prefix}'\")\n",
    "\n",
    "    return matching_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18f4e9bd-de61-4806-b314-6bcf988a2c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train-Qwen2-5-0-5B-rlvr-shots-8',\n",
       " 'train-Qwen2-5-0-5B-rlvr-shots-8-20251016181229')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_prefix, job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8294e44-2741-4207-90b3-7c882d11853d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5117530f-c55d-452f-8c10-63046149e2cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Inference configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf469f4-c71e-4cbb-9b45-3a6ad1e66e97",
   "metadata": {},
   "source": [
    "## Download model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4ff4d15-27cd-4def-b220-5925393a2fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded train-Qwen2-5-0-5B-rlvr-shots-8/train-Qwen2-5-0-5B-rlvr-shots-8-20251016181229/output/model.tar.gz to ./temp/train-Qwen2-5-0-5B-rlvr-shots-8-20251016181229/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "if default_prefix:\n",
    "    object_key = f\"{default_prefix}/{job_prefix}/{job_name}/output/model.tar.gz\"\n",
    "else:\n",
    "    object_key = f\"{job_prefix}/{job_name}/output/model.tar.gz\"\n",
    "\n",
    "\n",
    "\n",
    "# Local paths\n",
    "local_archive_path = f\"./temp/{job_name}/model.tar.gz\" #'./temp/model.tar.gz'\n",
    "local_model_dir = f\"./temp/extracted_model/{job_name}/\" #'./temp/extracted_model'\n",
    "\n",
    "# Create the /tmp directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(local_archive_path), exist_ok=True)\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "# Download the file from S3\n",
    "s3_client.download_file(bucket_name, object_key, local_archive_path)\n",
    "\n",
    "print(f\"Downloaded {object_key} to {local_archive_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec609ac7-d3f1-469f-baf9-db26c62e9af0",
   "metadata": {},
   "source": [
    "### Extract The model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "02b6758b-5646-4179-92a5-99127bc4bc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3305/3173588015.py:5: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=local_model_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted model files to ./temp/extracted_model/train-Qwen2-5-0-5B-rlvr-shots-8-20251016181229/\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# Extract the tar.gz file\n",
    "with tarfile.open(local_archive_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=local_model_dir)\n",
    "\n",
    "print(f\"Extracted model files to {local_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28824be-cb60-421e-8488-a4825cf5697d",
   "metadata": {},
   "source": [
    "### Evaluate The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8d3f2-59c0-4972-b129-8247f65b6f61",
   "metadata": {},
   "source": [
    "At first we need to merge the adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60fae9aa-6bb9-4bc7-abeb-55c62abff336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-17 20:01:32.963733: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760731292.975528   10150 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760731292.979224   10150 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-17 20:01:32.991611: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "from dataclasses import dataclass, field\n",
    "import tempfile\n",
    "from typing import Optional\n",
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from peft import PeftConfig, PeftModel, AutoPeftModelForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7770a7da-9bd5-4cb4-acab-696fe2240441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b4379843454ac5aa0876c8b04f7301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map: 100%|##########| 1319/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Load the dataset, tokenizer, and model ---\n",
    "# Use the GSM8K test split.\n",
    "dataset = GSM8K(split='test', include_answer=False, include_reasoning=True, few_shot=True, num_shots=8, seed=42, cot=True).dataset.shuffle(seed=42)\n",
    "\n",
    "dataset = dataset.select(range(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47e51b9a-3415-4356-992b-e06fd3a5ba55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question: A farmer has a total of 80 apples and oranges. If he has 30 apples, how many oranges does he have?\\nSolution: Let's think step by step. To determine the number of oranges, we subtract the number of apples from the total number of fruits. So, the number of oranges is 80 - 30 = 50.\\n#### The final answer is 50\\n\\nQuestion: Emily has 3 times as many pencils as Alice. If Alice has 15 pencils, how many pencils does Emily have?\\nSolution: Let's think step by step. To find out how many pencils Emily has, we multiply the number of pencils Alice has by 3. Alice has 15 pencils, so Emily has 15 * 3 = 45 pencils.\\n#### The final answer is 45\\n\\nQuestion: Samantha baked 40 cookies and wants to divide them equally into bags, with each bag containing 5 cookies. How many bags will Samantha need?\\nSolution: Let's think step by step. To find the number of bags needed, divide the total number of cookies by the number of cookies per bag. Thus, 40 divided by 5 equals 8.\\n#### The final answer is 8\\n\\nQuestion: Jack has collected 12 more marbles than Kevin. If Kevin has 27 marbles, how many marbles does Jack have?\\nSolution: Let's think step by step. To find how many marbles Jack has, we add 12 to the number of marbles Kevin has. So, Jack has 27 + 12 = 39 marbles.\\n#### The final answer is 39\\n\\nQuestion: Mark has $50 and buys a toy that costs $35. How much money does he have left?\\nSolution: Let's think step by step. To find out how much money Mark has left, subtract the cost of the toy from the total amount of money Mark has. So, $50 - $35 = $15.\\n#### The final answer is 15\\n\\nQuestion: There are 24 students in a classroom. If each group must have 4 students, how many groups can be formed?\\nSolution: Let's think step by step. To find how many groups can be formed, we divide the number of students by the number of students per group. So, 24 / 4 = 6 groups can be formed.\\n#### The final answer is 6\\n\\nQuestion: A pack of pencils costs $4. If you buy 7 packs, how much will you spend in total?\\nSolution: Let's think step by step. The total cost is found by multiplying the cost per pack by the number of packs. Hence, you spend 7 * $4 = $28.\\n#### The final answer is 28\\n\\nQuestion: A book has 240 pages, and Sarah reads 20 pages each day. How many days will it take her to finish the book?\\nSolution: Let's think step by step. Sarah reads 20 pages per day, so we divide the total pages by the number of pages she reads per day. Therefore, it takes her 240 / 20 = 12 days to finish the book.\\n#### The final answer is 12\\n\\nQuestion: Darrell and Allen's ages are in the ratio of 7:11. If their total age now is 162, calculate Allen's age 10 years from now.\\nSolution: Let's think step by step. \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e471206a-f9d2-4eee-9bdc-0946ba11861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_save_model(model_path_or_id, save_dir, save_tokenizer=True):\n",
    "    # Load the base model and tokenizer\n",
    "    config = PeftConfig.from_pretrained(model_path_or_id)\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path_or_id)\n",
    "    \n",
    "    # Add special tokens to the tokenizer\n",
    "    #tokenizer.add_special_tokens({'pad_token': ''})\n",
    "    \n",
    "    # Resize the token embeddings of the base model\n",
    "    base_model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    # Now load the PEFT model with the resized base model\n",
    "    model = PeftModel.from_pretrained(base_model, model_path_or_id)\n",
    "    \n",
    "    # Merge LoRA and base model and save\n",
    "    model = model.merge_and_unload()        \n",
    "    model.save_pretrained(save_dir, safe_serialization=True, max_shard_size=\"3GB\")\n",
    "  \n",
    "    # save tokenizer\n",
    "    if save_tokenizer:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path_or_id)\n",
    "        tokenizer.save_pretrained(save_dir) \n",
    "        \n",
    "def extract_answer(text):\n",
    "    \"\"\"\n",
    "    Extracts the numerical answer from the model's text output.\n",
    "    This function looks for the final number in the output, which is a common practice.\n",
    "    It removes commas to handle large numbers correctly.\n",
    "    \"\"\"\n",
    "    # The `re.findall` finds all sequences of digits, potentially with a minus sign.\n",
    "    numbers = re.findall(r'-?\\d+', text.replace(',', ''))\n",
    "    if numbers:\n",
    "        # We assume the final number is the answer.\n",
    "        return numbers[-1]\n",
    "    return None\n",
    "# Run the evaluation \n",
    "# For a full evaluation, you would generate a CoT prompt with examples from the train set.\n",
    "# For simplicity, this example uses a zero-shot prompt.\n",
    "# Few-shot CoT prompting is the standard approach for best results.\n",
    "def evaluate_on_gsm8k(model, tokenizer, dataset):\n",
    "    correct_count = 0\n",
    "    total_count = len(dataset)\n",
    "    model.eval()\n",
    "    for i, example in enumerate(dataset):\n",
    "        question = example[\"question\"]\n",
    "        ground_truth = example[\"final_answer\"]\n",
    "\n",
    "        # Create a simple prompt. For CoT, you would construct a more complex prompt.\n",
    "        prompt = example[\"prompt\"]\n",
    "\n",
    "        # Generate the model's response.\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, do_sample=False, max_new_tokens=1024, pad_token_id=tokenizer.eos_token_id)\n",
    "        model_output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract the model's predicted answer.\n",
    "        predicted_answer = extract_answer(model_output_text)\n",
    "\n",
    "        # print(f\"--- Example {i+1}/{total_count} ---\")\n",
    "        # print(f\"Question: {question}\")\n",
    "        # print(f\"Model Output: {model_output_text}\")\n",
    "        # print(f\"Extracted Answer: {predicted_answer}\")\n",
    "        # print(f\"Ground Truth: {ground_truth}\")\n",
    "        # print(f\"--------------------------------\")\n",
    "\n",
    "        if predicted_answer and predicted_answer == ground_truth:\n",
    "            correct_count += 1\n",
    "            #print(\"Status: Correct\\n\")\n",
    "        else:\n",
    "            correct_count=correct_count\n",
    "            #print(\"Status: Incorrect\\n\")\n",
    "\n",
    "    accuracy = correct_count / total_count\n",
    "    print(\"--- Evaluation Summary ---\")\n",
    "    print(f\"Total problems: {total_count}\")\n",
    "    print(f\"Correct predictions: {correct_count}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e5db1a7-e8da-4616-b9a4-ad5805883703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge_and_save_model(f\"./temp/extracted_model/{job_name}/Qwen2.5-0.5B-RL-VR-GRPO\", f\"./temp/merged-weights/{job_name}/\", save_tokenizer=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3afc4dd-710a-471f-9217-fa4b9101f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model and tokenizer\n",
    "#model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "model_name = f\"./temp/merged-weights/{job_name}/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab62e38-467f-437c-951e-04e039dcdfa5",
   "metadata": {},
   "source": [
    "#### results for 8 shots model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8232c-2147-4c8c-afe0-04cac9e2cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_on_gsm8k(model,tokenizer,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e95e17-ab47-4cb5-9b36-fed31b7f86cc",
   "metadata": {},
   "source": [
    "#### results for 4 shots model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a3d9a47-5831-49fc-9186-dd00ea059e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Summary ---\n",
      "Total problems: 50\n",
      "Correct predictions: 11\n",
      "Accuracy: 0.2200\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_gsm8k(model,tokenizer,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a15221-9c18-410c-8d8a-937f2c41c81d",
   "metadata": {},
   "source": [
    "#### results for 2 shots model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d93f7e21-23e6-4b75-a4e1-d43c2db7b8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Summary ---\n",
      "Total problems: 50\n",
      "Correct predictions: 6\n",
      "Accuracy: 0.1200\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_gsm8k(model,tokenizer,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3daa6d0-2163-4a25-a84e-d9cba178ea64",
   "metadata": {},
   "source": [
    "#### results for 0 shots model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eb899924-8053-4083-b715-817d52a69cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Summary ---\n",
      "Total problems: 50\n",
      "Correct predictions: 5\n",
      "Accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_gsm8k(model,tokenizer,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d7f0e-695b-4ff8-a29b-5c3a20c3af32",
   "metadata": {},
   "source": [
    "### Run evaluation on base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "70bff3ae-40ac-4bf3-8bef-08d4793d5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model and tokenizer from Hugging Face Hub.\n",
    "# You can replace this with your own model.\n",
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ef8aabc5-71ad-46b6-887b-e3fbd830d831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Summary ---\n",
      "Total problems: 50\n",
      "Correct predictions: 4\n",
      "Accuracy: 0.0800\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_gsm8k(base_model,tokenizer,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2f46e-3dcc-4ea4-8822-d1485bda0ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
