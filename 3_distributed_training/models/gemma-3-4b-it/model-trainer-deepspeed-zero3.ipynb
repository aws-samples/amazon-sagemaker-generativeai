{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad542e7-9ef8-41d1-9d6c-3c6c2efb7f19",
   "metadata": {},
   "source": [
    "# Fine-tune Google Gemma-3 4B with DeepSpeed ZeRO-3 on Amazon SageMaker AI using ModelTrainer\n",
    "\n",
    "In this notebook, we fine-tune [Google Gemma-3 4B Instruct](https://huggingface.co/google/gemma-3-4b-it) on Amazon SageMaker AI, using Python scripts and SageMaker ModelTrainer for executing a training job with DeepSpeed ZeRO-3 distributed training strategy.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Model**: google/gemma-3-4b-it\n",
    "- **Strategy**: DeepSpeed ZeRO-3 with CPU offloading\n",
    "- **Dataset**: HuggingFaceH4/Multilingual-Thinking (Apache 2.0 license)\n",
    "- **Training**: LoRA fine-tuning with merged weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca016c-d4fa-4213-a7b3-03b449551449",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907944ea-dbfb-4de0-9e13-1fd28c901031",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ./scripts/requirements.txt --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b6105-ecec-4213-b56d-589238844dca",
   "metadata": {},
   "source": [
    "## Setup Configuration\n",
    "\n",
    "Configure your Hugging Face token and optionally MLflow tracking server ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce51663-0171-4d54-b16e-f85e3cadb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"<HF_TOKEN>\"\n",
    "os.environ[\"model_id\"] = model_id\n",
    "os.environ[\"mlflow_uri\"] = \"arn:aws:sagemaker:region:account_id:mlflow-app/app-xxxxxxxx\"\n",
    "os.environ[\"mlflow_experiment_name\"] = \"gemma-3-4b-it-reasoning-multi-language\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82089d28-b97a-4956-83fb-d8c46d44fdb5",
   "metadata": {},
   "source": [
    "## Visualize and upload the dataset\n",
    "\n",
    "We are going to load [HuggingFaceH4/Multilingual-Thinking](https://huggingface.co/datasets/HuggingFaceH4/Multilingual-Thinking) dataset (Apache 2.0 license)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc5fa8-51b5-419c-9a87-784022e23e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481791d-9c86-4d32-a39a-918aff5e432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceH4/Multilingual-Thinking\", split=\"train\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df908a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train, test = train_test_split(train, test_size=10, random_state=42)\n",
    "\n",
    "print(\"Number of train elements: \", len(train))\n",
    "print(\"Number of val elements: \", len(val))\n",
    "print(\"Number of test elements: \", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368c020-e9a3-48b3-a53b-45404bba9482",
   "metadata": {},
   "source": [
    "Create a prompt template and format the dataset using Gemma-3 chat template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb8edd-35c0-4cf1-82d3-54417bdabd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "def prepare_dataset(sample):\n",
    "    messages = []\n",
    "    first_user_message = True\n",
    "    \n",
    "    for el in sample[\"messages\"]:\n",
    "        if el[\"role\"] == \"system\":\n",
    "            system_prompt = \"\"\"\n",
    "            You are an AI assistant that thinks in {language} but responds in English.\n",
    "\n",
    "            IMPORTANT: Follow this exact format for every response:\n",
    "            1. First, write your reasoning and thoughts inside <think>...</think> tags\n",
    "            2. Then, provide your final answer in English\n",
    "\n",
    "            Always think through the problem in {language}, then translate your conclusion to English for the final response.\n",
    "            \"\"\"\n",
    "            system_prompt = system_prompt.format(language=sample[\"reasoning_language\"])\n",
    "            system_prompt = textwrap.dedent(system_prompt).strip()\n",
    "        elif el[\"role\"] == \"user\":\n",
    "            if first_user_message:\n",
    "                first_user_message = False\n",
    "                messages.append({\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + el[\"content\"]})\n",
    "            else:\n",
    "                messages.append({\"role\": \"user\", \"content\": el[\"content\"]})\n",
    "        else:\n",
    "            if el[\"thinking\"] is not None and el[\"thinking\"] != \"\" and el[\"thinking\"] != \"null\":\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"<think>\\n{el['thinking']}\\n</think>\\n{el['content']}\",\n",
    "                })\n",
    "            else:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": el[\"content\"]})\n",
    "\n",
    "    sample[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9cbedd-7403-467e-8cc6-1d2550d8b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from random import randint\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "val_dataset = Dataset.from_pandas(val)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"val\": val_dataset})\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    prepare_dataset, remove_columns=list(train_dataset.features)\n",
    ")\n",
    "\n",
    "print(train_dataset[randint(0, len(dataset))][\"text\"])\n",
    "\n",
    "val_dataset = dataset[\"val\"].map(\n",
    "    prepare_dataset, remove_columns=list(val_dataset.features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e667af-8197-4d2f-8432-82db6a1d3006",
   "metadata": {},
   "source": [
    "### Upload to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f29e5-4aed-4939-8d51-ad3c5268299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import shutil\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302814d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if default_prefix:\n",
    "    input_path = f\"{default_prefix}/datasets/gemma-3-4b-it-fine-tuning-dsz3\"\n",
    "else:\n",
    "    input_path = f\"datasets/gemma-3-4b-it-fine-tuning-dsz3\"\n",
    "\n",
    "train_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/train/dataset.json\"\n",
    "val_dataset_s3_path = f\"s3://{bucket_name}/{input_path}/val/dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d0321-1bd5-4c62-845a-bb1b9a3891a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"./data/train\", exist_ok=True)\n",
    "os.makedirs(\"./data/val\", exist_ok=True)\n",
    "\n",
    "train_dataset.to_json(\"./data/train/dataset.json\", orient=\"records\")\n",
    "val_dataset.to_json(\"./data/val/dataset.json\", orient=\"records\")\n",
    "\n",
    "s3_client.upload_file(\"./data/train/dataset.json\", bucket_name, f\"{input_path}/train/dataset.json\")\n",
    "s3_client.upload_file(\"./data/val/dataset.json\", bucket_name, f\"{input_path}/val/dataset.json\")\n",
    "\n",
    "shutil.rmtree(\"./data\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(val_dataset_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457beda-117d-4782-9f04-0680c199e98a",
   "metadata": {},
   "source": [
    "## Model fine-tuning\n",
    "\n",
    "We are now ready to fine-tune our model. We will use the [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) from transformers to fine-tune our model. We prepared a script [train.py](./scripts/train.py) which loads the dataset from disk, prepares the model, tokenizer and starts the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60599b52",
   "metadata": {},
   "source": [
    "### Training configurations\n",
    "\n",
    "For configuration we use `TrlParser`, that allows us to provide hyperparameters in a `yaml` file. This yaml will be uploaded and provided to Amazon SageMaker similar to our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5aaaf-7d2f-4aae-87af-1b9e6b11b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./args.yaml <<EOF\n",
    "model_id: \"${model_id}\"                           # Hugging Face model id\n",
    "mlflow_uri: \"${mlflow_uri}\"                       # MLflow tracking server URI\n",
    "mlflow_experiment_name: \"${mlflow_experiment_name}\" # MLflow experiment name\n",
    "# sagemaker specific parameters\n",
    "output_dir: \"/opt/ml/model\"                       # path to where SageMaker will upload the model \n",
    "checkpoint_dir: \"/opt/ml/checkpoints/\"            # directory for saving training checkpoints\n",
    "train_dataset_path: \"/opt/ml/input/data/train/\"   # path to where S3 saves train dataset\n",
    "val_dataset_path: \"/opt/ml/input/data/val/\"       # path to where S3 saves test dataset\n",
    "token: \"${HF_TOKEN}\"                              # Hugging Face API token\n",
    "merge_weights: true                               # merge weights in the base model\n",
    "# training parameters\n",
    "apply_truncation: true                           # apply truncation to datasets\n",
    "attn_implementation: \"flash_attention_2\"         # attention implementation type\n",
    "learning_rate: 2e-5                              # learning rate scheduler\n",
    "num_train_epochs: 10                             # number of training epochs\n",
    "per_device_train_batch_size: 1                   # batch size per device during training\n",
    "per_device_eval_batch_size: 2                    # batch size for evaluation\n",
    "gradient_accumulation_steps: 16                  # number of steps before performing a backward/update pass\n",
    "gradient_checkpointing: true                     # use gradient checkpointing\n",
    "torch_dtype: \"bfloat16\"                          # float precision type\n",
    "bf16: true                                       # use bfloat16 precision\n",
    "tf32: true                                       # use tf32 precision\n",
    "ignore_data_skip: true                           # skip data loading errors\n",
    "logging_strategy: \"steps\"                        # logging strategy\n",
    "logging_steps: 1                                 # log every N steps\n",
    "log_on_each_node: false                          # disable logging on each node\n",
    "ddp_find_unused_parameters: false                # DDP unused parameter detection\n",
    "save_total_limit: 1                              # maximum number of checkpoints to keep\n",
    "save_steps: 100                                  # Save checkpoint every this many steps\n",
    "warmup_steps: 50                                 # number of warmup steps\n",
    "weight_decay: 0.01                               # weight decay coefficient\n",
    "dataloader_pin_memory: false                     # pin memory for dataloader\n",
    "# LoRA parameters\n",
    "load_in_4bit: false                              # enable 4-bit quantization\n",
    "lora_r: 16                                       # LoRA rank\n",
    "lora_alpha: 32                                   # LoRA alpha parameter\n",
    "lora_dropout: 0.1                                # LoRA dropout rate\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70937e95-114e-40e1-b26a-49cc1cbd803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "if default_prefix:\n",
    "    input_path = f\"s3://{bucket_name}/{default_prefix}/datasets/gemma-3-4b-it-fine-tuning-dsz3\"\n",
    "else:\n",
    "    input_path = f\"s3://{bucket_name}/datasets/gemma-3-4b-it-fine-tuning-dsz3\"\n",
    "\n",
    "model_yaml = \"args.yaml\"\n",
    "train_config_s3_path = S3Uploader.upload(local_path=model_yaml, desired_s3_uri=f\"{input_path}/config\")\n",
    "\n",
    "os.remove(\"./args.yaml\")\n",
    "\n",
    "print(f\"Training config uploaded to:\")\n",
    "print(train_config_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746cf6d",
   "metadata": {},
   "source": [
    "### DeepSpeed ZeRO-3 configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./accelerate_config.yaml <<EOF\n",
    "compute_environment: LOCAL_MACHINE\n",
    "debug: false\n",
    "deepspeed_config:\n",
    "  deepspeed_multinode_launcher: standard\n",
    "  offload_optimizer_device: cpu\n",
    "  offload_param_device: cpu\n",
    "  zero3_init_flag: true\n",
    "  zero3_save_16bit_model: true\n",
    "  zero_stage: 3\n",
    "distributed_type: DEEPSPEED\n",
    "downcast_bf16: 'no'\n",
    "main_training_function: main\n",
    "mixed_precision: bf16\n",
    "rdzv_backend: c10d                        # static for single node, c10d for single and multi-node\n",
    "same_network: true\n",
    "tpu_env: []\n",
    "tpu_use_cluster: false\n",
    "tpu_use_sudo: false\n",
    "use_cpu: false\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "if default_prefix:\n",
    "    input_path = f\"s3://{bucket_name}/{default_prefix}/datasets/gemma-3-4b-it-fine-tuning-dsz3\"\n",
    "else:\n",
    "    input_path = f\"s3://{bucket_name}/datasets/gemma-3-4b-it-fine-tuning-dsz3\"\n",
    "\n",
    "model_yaml = \"accelerate_config.yaml\"\n",
    "train_accelerate_config_s3_path = S3Uploader.upload(\n",
    "    local_path=model_yaml, desired_s3_uri=f\"{input_path}/accelerate_config\"\n",
    ")\n",
    "\n",
    "os.remove(\"./accelerate_config.yaml\")\n",
    "\n",
    "print(f\"Accelerate config uploaded to:\")\n",
    "print(train_accelerate_config_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329683c-6662-45d3-b864-9cb575f92599",
   "metadata": {},
   "source": [
    "## Fine-tune model\n",
    "\n",
    "Below estimator will train the model with LoRA, merge the adapter in the base model and save in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178118a-0f45-4e5f-9bb1-7e5dee146b62",
   "metadata": {},
   "source": [
    "### Get PyTorch image_uri\n",
    "\n",
    "We are going to use the native PyTorch container image, pre-built for Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5a03c-7660-4729-bf98-67ecb8ffa508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.config import load_sagemaker_config\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "configs = load_sagemaker_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cecfd-e640-4527-99d4-cb3cec9093b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml.g5.12xlarge has 4x A10G GPUs\n",
    "instance_type = \"ml.g5.12xlarge\"\n",
    "instance_count = 1\n",
    "\n",
    "instance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df7700-7c66-4af8-aea0-da0e5af493bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"2.7.1\",\n",
    "    instance_type=instance_type,\n",
    "    image_scope=\"training\",\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cabb4d-b0b2-498c-95cb-41ed7d05ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.modules.configs import (\n",
    "    CheckpointConfig,\n",
    "    Compute,\n",
    "    OutputDataConfig,\n",
    "    SourceCode,\n",
    "    StoppingCondition,\n",
    ")\n",
    "from sagemaker.modules.distributed import Torchrun\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "\n",
    "args = [\n",
    "    \"--entrypoint\",\n",
    "    \"train.py\",\n",
    "    \"--accelerate_config\",\n",
    "    \"/opt/ml/input/data/accelerate_config/accelerate_config.yaml\",\n",
    "    \"--config\",\n",
    "    \"/opt/ml/input/data/config/args.yaml\",\n",
    "]\n",
    "\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"./scripts\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    command=f\"bash sm_accelerate_train.sh {' '.join(args)}\",\n",
    ")\n",
    "\n",
    "compute_configs = Compute(\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    keep_alive_period_in_seconds=0,\n",
    ")\n",
    "\n",
    "job_name = f\"train-{model_id.split('/')[-1].replace('.', '-')}-dsz3\"\n",
    "\n",
    "if default_prefix:\n",
    "    output_path = f\"s3://{bucket_name}/{default_prefix}/{job_name}\"\n",
    "else:\n",
    "    output_path = f\"s3://{bucket_name}/{job_name}\"\n",
    "\n",
    "model_trainer = ModelTrainer(\n",
    "    training_image=image_uri,\n",
    "    source_code=source_code,\n",
    "    base_job_name=job_name,\n",
    "    compute=compute_configs,\n",
    "    stopping_condition=StoppingCondition(max_runtime_in_seconds=18000),\n",
    "    output_data_config=OutputDataConfig(\n",
    "        s3_output_path=output_path, compression_type=\"NONE\"\n",
    "    ),\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        s3_uri=output_path + \"/checkpoint\", local_path=\"/opt/ml/checkpoints\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a386bd9-172c-485c-af45-ebc1d126470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.modules.configs import InputData\n",
    "\n",
    "train_input = InputData(\n",
    "    channel_name=\"train\",\n",
    "    data_source=train_dataset_s3_path,\n",
    ")\n",
    "\n",
    "val_input = InputData(\n",
    "    channel_name=\"val\",\n",
    "    data_source=val_dataset_s3_path,\n",
    ")\n",
    "\n",
    "config_input = InputData(\n",
    "    channel_name=\"config\",\n",
    "    data_source=train_config_s3_path,\n",
    ")\n",
    "\n",
    "accelerate_config_input = InputData(\n",
    "    channel_name=\"accelerate_config\",\n",
    "    data_source=train_accelerate_config_s3_path,\n",
    ")\n",
    "\n",
    "data = [train_input, val_input, config_input, accelerate_config_input]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e13aa-1df2-43fc-bae4-15f5b7113191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training job\n",
    "model_trainer.train(input_data_config=data, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81686e-d27f-4c7b-bec6-f596e7dbaa32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model Deployment\n",
    "\n",
    "In the following sections, we are going to deploy the fine-tuned model on an Amazon SageMaker Real-time endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb892b35-ab33-4964-9947-f9487a1e50cb",
   "metadata": {},
   "source": [
    "## Load Fine-Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50ff8a-842c-45bc-aa55-4a5e87f2b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35481eff-1142-46f3-8e38-50a1bdadba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "default_prefix = sagemaker_session.default_bucket_prefix\n",
    "job_prefix = f\"train-{model_id.split('/')[-1].replace('.', '-')}-dsz3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed118e7-1c80-4392-8ea5-147b63fc2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    matching_jobs = []\n",
    "    next_token = None\n",
    "\n",
    "    while True:\n",
    "        search_params = {\n",
    "            'Resource': 'TrainingJob',\n",
    "            'SearchExpression': {\n",
    "                'Filters': [\n",
    "                    {'Name': 'TrainingJobName', 'Operator': 'Contains', 'Value': job_name_prefix},\n",
    "                    {'Name': 'TrainingJobStatus', 'Operator': 'Equals', 'Value': \"Completed\"}\n",
    "                ]\n",
    "            },\n",
    "            'SortBy': 'CreationTime',\n",
    "            'SortOrder': 'Descending',\n",
    "            'MaxResults': 100\n",
    "        }\n",
    "\n",
    "        if next_token:\n",
    "            search_params['NextToken'] = next_token\n",
    "\n",
    "        search_response = sagemaker_client.search(**search_params)\n",
    "\n",
    "        matching_jobs.extend([\n",
    "            job['TrainingJob']['TrainingJobName'] \n",
    "            for job in search_response['Results']\n",
    "            if job['TrainingJob']['TrainingJobName'].startswith(job_name_prefix)\n",
    "        ])\n",
    "\n",
    "        next_token = search_response.get('NextToken')\n",
    "        if not next_token or matching_jobs:\n",
    "            break\n",
    "\n",
    "    if not matching_jobs:\n",
    "        raise ValueError(f\"No completed training jobs found starting with prefix '{job_name_prefix}'\")\n",
    "\n",
    "    return matching_jobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4e9bd-de61-4806-b314-6bcf988a2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eeba4b-cfc9-4aae-be86-8d2f3c4e5cb0",
   "metadata": {},
   "source": [
    "### Inference configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ef485-b13b-43a7-a523-eacbdddbb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29f2d8-b3b3-4b27-a0d2-e49812f56a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.2xlarge\"  # Single A10G GPU is sufficient for Gemma-3 4B\n",
    "health_check_timeout = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f062e4-e829-40f4-a613-bf16ad503829",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"djl-lmi\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"latest\"\n",
    ")\n",
    "\n",
    "image_uri = image_uri.split(\"/\")[0] + \"/djl-inference:0.36.0-lmi18.0.0-cu128\"\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce2073-8921-4f73-b2ed-41129bd0519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if default_prefix:\n",
    "    model_data_path = f\"s3://{bucket_name}/{default_prefix}/{job_prefix}/{job_name}/output/model/\"\n",
    "else:\n",
    "    model_data_path = f\"s3://{bucket_name}/{job_prefix}/{job_name}/output/model/\"\n",
    "\n",
    "model_data = {\n",
    "    \"S3DataSource\": {\n",
    "        \"S3Uri\": model_data_path,\n",
    "        \"S3DataType\": \"S3Prefix\",\n",
    "        \"CompressionType\": \"None\",\n",
    "    }\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_data,\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
    "        \"SERVING_FAIL_FAST\": \"true\",\n",
    "        \"OPTION_ASYNC_MODE\": \"true\",\n",
    "        \"OPTION_ROLLING_BATCH\": \"disable\",\n",
    "        \"OPTION_TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "        \"OPTION_ENTRYPOINT\": \"djl_python.lmi_vllm.vllm_async_service\",\n",
    "        \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "        \"OPTION_MODEL_LOADING_TIMEOUT\": \"3600\"\n",
    "    },\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30036f-9231-4de4-a03f-1297d2b6a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-djl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9035076-ac69-4859-9824-dcbf07c0f2b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    "    model_data_download_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d0cac-4af1-4034-9f88-35861396c228",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6e8c1-5a3b-459f-8763-febab2b8f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61094a1-1fa9-495f-8343-aa27d9c4ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-djl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b040d-b8f4-4be0-9687-b28eff520236",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586b889-6554-4d75-b295-e7dc99673cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "eval_dataset = []\n",
    "\n",
    "index = 1\n",
    "for sample in test_dataset:\n",
    "    print(\"Processing item \", index)\n",
    "\n",
    "    messages = []\n",
    "    message_index = 0\n",
    "    for el in sample[\"messages\"]:\n",
    "        if message_index == len(sample[\"messages\"]) - 1:\n",
    "            break\n",
    "\n",
    "        if el[\"role\"] == \"system\":\n",
    "            system_prompt = \"\"\"\n",
    "            You are an AI assistant that thinks in {language} but responds in English.\n",
    "\n",
    "            IMPORTANT: Follow this exact format for every response:\n",
    "            1. First, write your reasoning and thoughts inside <think>...</think> tags\n",
    "            2. Then, provide your final answer in English\n",
    "\n",
    "            Always think through the problem in {language}, then translate your conclusion to English for the final response.\n",
    "            \"\"\"\n",
    "            system_prompt = system_prompt.format(language=sample[\"reasoning_language\"])\n",
    "            system_prompt = textwrap.dedent(system_prompt).strip()\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        elif el[\"role\"] == \"user\":\n",
    "            messages.append({\"role\": \"user\", \"content\": el[\"content\"]})\n",
    "        else:\n",
    "            if el[\"thinking\"] is not None and el[\"thinking\"] != \"\" and el[\"thinking\"] != \"null\":\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"<think>\\n{el['thinking']}\\n</think>\\n{el['content']}\",\n",
    "                })\n",
    "            else:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": el[\"content\"]})\n",
    "\n",
    "        message_index += 1\n",
    "\n",
    "    response = predictor.predict({\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "        \"repetition_penalty\": 1.15,\n",
    "        \"do_sample\": True,\n",
    "    })\n",
    "\n",
    "    eval_dataset.append([\n",
    "        [el[\"content\"] for el in messages if el[\"role\"] == \"system\"][0],\n",
    "        [el[\"content\"] for el in messages if el[\"role\"] == \"user\"],\n",
    "        response[\"choices\"][0][\"message\"][\"content\"],\n",
    "    ])\n",
    "\n",
    "    index += 1\n",
    "    print(\"**********************************************\")\n",
    "\n",
    "eval_dataset_df = pd.DataFrame(eval_dataset, columns=[\"system\", \"question\", \"answer\"])\n",
    "eval_dataset_df.to_json(\"./eval_dataset_results.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff5d47-62d5-4751-828c-c6f998c33b16",
   "metadata": {},
   "source": [
    "### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb50d8-51f4-42fc-8e54-1b6bfe1179fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922957c-e7e3-46e3-86ea-8a8134c96bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-djl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00feef6-e758-434d-8c36-b2212cccebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aebbc6-5761-44a7-949d-45b2fffd2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
