{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "auto",
   "metadata": {},
   "source": [
    "# üöÄ Model Deployment for Phishing Detection\n",
    "\n",
    "**Purpose**: Deploy the fine-tuned Qwen2.5-1.5B model as a real-time SageMaker endpoint.\n",
    "\n",
    "This notebook:\n",
    "- Loads trained model from S3\n",
    "- Configures vLLM for text classification\n",
    "- Creates SageMaker endpoint with LMI container\n",
    "- Tests inference with sample emails\n",
    "\n",
    "## Prerequisites\n",
    "- **Run `02_model_training.ipynb` first**\n",
    "- Trained model artifacts in S3\n",
    "- Budget: ~$1.41/hour for ml.g5.xlarge endpoint\n",
    "\n",
    "## Next Steps\n",
    "After deployment ‚Üí `04_benchmarking.ipynb`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee1fac",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq \"sagemaker==2.253.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e595873",
   "metadata": {},
   "source": [
    "## 2. Load Variables from Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r model_s3_uri\n",
    "%store -r training_job_name\n",
    "%store -r NUM_LABELS\n",
    "%store -r region\n",
    "%store -r role\n",
    "%store -r sagemaker_session_bucket\n",
    "\n",
    "# Verify\n",
    "try:\n",
    "    print(\"‚úÖ Variables loaded:\")\n",
    "    print(f\"  Model S3 URI: {model_s3_uri}\")\n",
    "    print(f\"  Training job: {training_job_name}\")\n",
    "    print(f\"  Number of labels: {NUM_LABELS}\")\n",
    "except NameError:\n",
    "    print(\"‚ùå Run 02_model_training.ipynb first!\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56361e22",
   "metadata": {},
   "source": [
    "## 3. SageMaker Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(boto3.Session(region_name=region))\n",
    "\n",
    "print(f\"SageMaker role: {role}\")\n",
    "print(f\"SageMaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f7710",
   "metadata": {},
   "source": [
    "## 4. Configure Deployment\n",
    "\n",
    "We'll use SageMaker LMI containers with vLLM for optimized inference.\n",
    "\n",
    "### Why vLLM for Text Classification?\n",
    "- **Fast**: Optimized for single-token generation (label prediction)\n",
    "- **Efficient**: Lower latency than full text generation\n",
    "- **Cost-effective**: Can run on smaller instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment configuration\n",
    "inference_instance_type = \"ml.g5.xlarge\"\n",
    "timeout = 900\n",
    "image_lmi_v18 = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.36.0-lmi18.0.0-cu128\"\n",
    "\n",
    "print(f\"Instance type: {inference_instance_type}\")\n",
    "print(f\"Container: {image_lmi_v18}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735db4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vLLM configuration for text classification\n",
    "env_vars = {\n",
    "    \"HF_MODEL_ID\": model_s3_uri,\n",
    "    \"NUM_GPUS\": \"1\",\n",
    "    \"OPTION_TENSOR_PARALLELISM\": \"1\",\n",
    "    \"OPTION_TASK\": \"text-classification\",\n",
    "    \"OPTION_ENFORCE_EAGER\": \"true\",\n",
    "}\n",
    "\n",
    "print(\"‚úÖ vLLM environment configured for text classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e0395",
   "metadata": {},
   "source": [
    "## 5. Create SageMaker Model\n",
    "\n",
    "This creates a model resource that references our trained model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82616f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = sagemaker.utils.name_from_base(\"qwen-phishing\")\n",
    "\n",
    "from sagemaker_core.shapes import ContainerDefinition\n",
    "from sagemaker_core.resources import Model\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "\n",
    "model = Model.create(\n",
    "    model_name=model_name,\n",
    "    primary_container=ContainerDefinition(\n",
    "        image=image_lmi_v18,\n",
    "        environment=env_vars\n",
    "    ),\n",
    "    execution_role_arn=role,\n",
    "    session=boto_session,\n",
    "    region=region,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model created: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc299317",
   "metadata": {},
   "source": [
    "## 6. Deploy Endpoint\n",
    "\n",
    "This will create a real-time inference endpoint. Deployment takes ~5-10 minutes.\n",
    "\n",
    "**Cost**: ~$1.41/hour while endpoint is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_core.shapes import ProductionVariant, ProductionVariantRoutingConfig\n",
    "from sagemaker_core.resources import EndpointConfig, Endpoint\n",
    "\n",
    "print(f\"üöÄ Deploying endpoint: {model_name}\")\n",
    "print(\"This will take ~5-10 minutes...\\n\")\n",
    "\n",
    "endpoint = Endpoint.create(\n",
    "    endpoint_name=model_name,\n",
    "    endpoint_config_name=EndpointConfig.create(\n",
    "        endpoint_config_name=model_name,\n",
    "        production_variants=[\n",
    "            ProductionVariant(\n",
    "                variant_name=model_name,\n",
    "                initial_instance_count=1,\n",
    "                instance_type=inference_instance_type,\n",
    "                model_name=model,\n",
    "                container_startup_health_check_timeout_in_seconds=timeout,\n",
    "                model_data_download_timeout_in_seconds=timeout,\n",
    "                routing_config=ProductionVariantRoutingConfig(\n",
    "                    routing_strategy=\"LEAST_OUTSTANDING_REQUESTS\"\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "endpoint.wait_for_status(\"InService\")\n",
    "\n",
    "print(f\"\\n‚úÖ Endpoint deployed and in service!\")\n",
    "print(f\"Endpoint name: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c793dd9",
   "metadata": {},
   "source": [
    "## 7. Test Inference\n",
    "\n",
    "Create a helper function to invoke the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4946d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_retry_config = Config(retries={'max_attempts': 1})\n",
    "runtime_client = boto3.client(\"sagemaker-runtime\", config=no_retry_config)\n",
    "\n",
    "def invoke_classification_endpoint(ep_name, texts):\n",
    "    \"\"\"\n",
    "    Invoke SageMaker LMI classification endpoint.\n",
    "    \n",
    "    Args:\n",
    "        ep_name: SageMaker endpoint name\n",
    "        texts: Single string or list of strings to classify\n",
    "    \n",
    "    Returns:\n",
    "        dict: Classification results with probabilities\n",
    "    \"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    \n",
    "    payload = {\n",
    "        \"inputs\": texts\n",
    "    }\n",
    "    \n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=ep_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Inference function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474feac",
   "metadata": {},
   "source": [
    "### 7.1 Test Single Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a phishing example\n",
    "test_email = \"Urgent! Click here to verify your account immediately!\"\n",
    "\n",
    "result = invoke_classification_endpoint(model_name, test_email)\n",
    "\n",
    "print(f\"Email: {test_email}\")\n",
    "print(f\"\\nResult:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b91bc",
   "metadata": {},
   "source": [
    "### 7.2 Test Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382bec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple emails\n",
    "test_emails = [\n",
    "    \"Urgent! Click here to verify your account!\",\n",
    "    \"Meeting scheduled for tomorrow at 2pm\",\n",
    "    \"You've won $1,000,000! Claim your prize now!\",\n",
    "    \"Please review the attached quarterly report\",\n",
    "]\n",
    "\n",
    "results = invoke_classification_endpoint(model_name, test_emails)\n",
    "\n",
    "print(\"Batch classification results:\\n\")\n",
    "for i, (email, result) in enumerate(zip(test_emails, results)):\n",
    "    print(f\"{i+1}. {email[:50]}...\")\n",
    "    print(f\"   Result: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ca047",
   "metadata": {},
   "source": [
    "## 8. Store Variables for Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba81728",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = model_name\n",
    "\n",
    "%store endpoint_name\n",
    "%store model_name\n",
    "\n",
    "print(\"\\n‚úÖ Variables stored:\")\n",
    "print(f\"  Endpoint name: {endpoint_name}\")\n",
    "print(f\"  Model name: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a361bfc",
   "metadata": {},
   "source": [
    "## ‚úÖ Deployment Complete!\n",
    "\n",
    "### What We Accomplished:\n",
    "1. ‚úÖ Loaded trained model from S3\n",
    "2. ‚úÖ Configured vLLM for text classification\n",
    "3. ‚úÖ Created SageMaker model resource\n",
    "4. ‚úÖ Deployed real-time endpoint\n",
    "5. ‚úÖ Tested inference (single + batch)\n",
    "6. ‚úÖ Stored endpoint info for benchmarking\n",
    "\n",
    "### Your Endpoint is Live!\n",
    "- **Endpoint name**: Stored in `endpoint_name`\n",
    "- **Instance type**: ml.g5.xlarge\n",
    "- **Cost**: ~$1.41/hour while running\n",
    "\n",
    "### Next Steps:\n",
    "**Proceed to `04_benchmarking.ipynb`** to evaluate endpoint performance.\n",
    "\n",
    "‚ö†Ô∏è **Remember**: Delete the endpoint when done to avoid charges!\n",
    "\n",
    "---\n",
    "\n",
    "**Deployment Time**: ~5-10 minutes  \n",
    "**Hourly Cost**: ~$1.41"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
