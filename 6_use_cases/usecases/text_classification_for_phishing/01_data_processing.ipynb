{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ðŸ“Š Data Processing for Phishing Detection\n",
    "\n",
    "**Purpose**: Prepare the phishing detection dataset for model training.\n",
    "\n",
    "This notebook handles:\n",
    "- Loading the raw dataset from HuggingFace\n",
    "- Preprocessing email content and labels\n",
    "- Creating train/validation/test splits\n",
    "- Analyzing dataset statistics\n",
    "- Exporting to JSONL format\n",
    "- Uploading processed data to S3\n",
    "\n",
    "## Prerequisites\n",
    "- SageMaker notebook instance or local environment\n",
    "- AWS credentials configured\n",
    "- Internet access to download HuggingFace datasets\n",
    "\n",
    "## Expected Outputs\n",
    "- `datasets/train.jsonl` - Training dataset (~23k samples)\n",
    "- `datasets/validation.jsonl` - Validation dataset (~4k samples)\n",
    "- `datasets/test.jsonl` - Test dataset (~3.7k samples)\n",
    "- S3 paths stored in magic variables for next notebook\n",
    "\n",
    "## Next Steps\n",
    "After running this notebook, proceed to `02_model_training.ipynb`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "Install only the dependencies needed for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pip-install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y autogluon-multimodal autogluon-core autogluon-features autogluon-tabular autogluon-timeseries\n",
    "!pip install -Uq \"datasets==4.3.0\" \"sagemaker==2.253.1\" \"pandas>=1.5.0\" \"scikit-learn>=1.3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datasets import load_dataset, DatasetDict, Dataset, ClassLabel\n",
    "from sagemaker.s3 import S3Uploader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sagemaker-setup",
   "metadata": {},
   "source": [
    "## 2. SageMaker Configuration\n",
    "\n",
    "Set up AWS session, role, and S3 bucket for data storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sagemaker-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "sess = sagemaker.Session(boto3.Session(region_name=region))\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker role ARN: {role}\")\n",
    "print(f\"SageMaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"SageMaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-prep",
   "metadata": {},
   "source": [
    "## 3. Dataset Loading\n",
    "\n",
    "Load the [`drorrabin/phishing_emails-data`](https://huggingface.co/datasets/drorrabin/phishing_emails-data) dataset from HuggingFace.\n",
    "\n",
    "### Dataset Overview:\n",
    "- **Purpose**: Email phishing detection\n",
    "- **Size**: ~27k training samples, ~3.7k test samples\n",
    "- **Labels**: Binary (0=Safe, 1=Phishing)\n",
    "- **Format**: Email text with classification labels\n",
    "- **Source**: Optimized for LLM fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"drorrabin/phishing_emails-data\"\n",
    "NUM_LABELS = 2  # Binary classification\n",
    "\n",
    "LABEL_NAMES = {\n",
    "    0: \"Safe\",      # Legitimate content\n",
    "    1: \"Phishing\"   # Phishing/malicious content\n",
    "}\n",
    "\n",
    "print(\"Loading phishing dataset...\")\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "\n",
    "raw_dataset = load_dataset(\n",
    "    path=DATASET_NAME,\n",
    "    revision=\"9f364df1d4fa9ec50601bf2ddc293c71a469f749\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dataset loaded successfully!\")\n",
    "print(f\"Available splits: {list(raw_dataset.keys())}\")\n",
    "print(f\"Total training samples: {len(raw_dataset['train'])}\")\n",
    "print(f\"Total test samples: {len(raw_dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample data (raw):\")\n",
    "sample = random.choice(raw_dataset['train'])\n",
    "print(json.dumps(sample, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-dataset",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "The raw dataset format includes:\n",
    "- **text**: Full prompt with email content + answer (e.g., \"Is the following email safe or phishing??\\n\\n[EMAIL]\\n\\nEmail type is: [LABEL]\")\n",
    "- **email_type**: String label (\"safe email\" or \"phishing email\")\n",
    "\n",
    "We need to:\n",
    "1. Extract just the email content (remove prompt and answer)\n",
    "2. Convert string labels to binary integers (0=safe, 1=phishing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_phishing_email(example):\n",
    "    \"\"\"\n",
    "    Extract email content and convert label to binary.\n",
    "    \n",
    "    Input format:\n",
    "        'Is the following email safe or phishing??\\n\\n[EMAIL CONTENT]\\n\\nEmail type is: [LABEL]'\n",
    "    \n",
    "    Output:\n",
    "        - text: Just the email content\n",
    "        - label: 0 (safe) or 1 (phishing)\n",
    "    \"\"\"\n",
    "    text = example['text']\n",
    "    \n",
    "    # Remove the prompt prefix\n",
    "    if text.startswith(\"Is the following email safe or phishing??\"):\n",
    "        text = text.replace(\"Is the following email safe or phishing??\", \"\").strip()\n",
    "    \n",
    "    # Remove the answer suffix\n",
    "    if \"Email type is:\" in text:\n",
    "        text = text.split(\"Email type is:\")[0].strip()\n",
    "    \n",
    "    # Convert label to binary\n",
    "    label = int('phishing' in example['email_type'].lower())\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'label': label\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing preprocessing...\")\n",
    "sample = random.choice(raw_dataset['train'])\n",
    "processed = preprocess_phishing_email(sample)\n",
    "\n",
    "print(f\"\\nOriginal length: {len(sample['text'])} chars\")\n",
    "print(f\"Processed length: {len(processed['text'])} chars\")\n",
    "print(f\"Original label: {sample['email_type']}\")\n",
    "print(f\"Processed label: {processed['label']} ({LABEL_NAMES[processed['label']]})\")\n",
    "print(f\"\\nProcessed text preview (first 200 chars):\\n{processed['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apply-preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nApplying preprocessing to entire dataset...\")\n",
    "raw_dataset = raw_dataset.map(\n",
    "    preprocess_phishing_email,\n",
    "    remove_columns=['email_type'],\n",
    "    desc=\"Preprocessing\"\n",
    ")\n",
    "\n",
    "print(\"Converting label to ClassLabel for stratified splitting...\")\n",
    "raw_dataset = raw_dataset.cast_column(\n",
    "    'label',\n",
    "    ClassLabel(names=['safe', 'phishing'])\n",
    ")\n",
    "\n",
    "print(\"âœ… Preprocessing complete!\")\n",
    "print(f\"\\nProcessed sample:\")\n",
    "print(random.choice(raw_dataset['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-analysis",
   "metadata": {},
   "source": [
    "## 5. Dataset Analysis\n",
    "\n",
    "Analyze the dataset to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "label-dist-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_label_distribution(dataset, split_name=\"train\"):\n",
    "    \"\"\"\n",
    "    Analyze and print label distribution for a dataset split.\n",
    "    \n",
    "    Args:\n",
    "        dataset: HuggingFace DatasetDict, Dataset, or DataFrame with 'label' column\n",
    "        split_name: Name of the split for display or to extract from DatasetDict\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistics including counts and percentages\n",
    "    \"\"\"\n",
    "    if isinstance(dataset, DatasetDict):\n",
    "        df = pd.DataFrame(dataset[split_name])\n",
    "    elif isinstance(dataset, Dataset):\n",
    "        df = pd.DataFrame(dataset)\n",
    "    else:\n",
    "        df = dataset\n",
    "    \n",
    "    safe_count = (df['label'] == 0).sum()\n",
    "    phishing_count = (df['label'] == 1).sum()\n",
    "    safe_pct = (safe_count / len(df)) * 100\n",
    "    phishing_pct = (phishing_count / len(df)) * 100\n",
    "    \n",
    "    print(f\"\\nðŸ“Š {split_name} Label Distribution:\")\n",
    "    print(f\"  Total samples: {len(df)}\")\n",
    "    print(f\"  Safe (0): {safe_count} ({safe_pct:.1f}%)\")\n",
    "    print(f\"  Phishing (1): {phishing_count} ({phishing_pct:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'total': len(df),\n",
    "        'safe_count': safe_count,\n",
    "        'phishing_count': phishing_count,\n",
    "        'safe_pct': safe_pct,\n",
    "        'phishing_pct': phishing_pct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-labels",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_label_distribution(raw_dataset, split_name=\"train\")\n",
    "_ = analyze_label_distribution(raw_dataset, split_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text-length-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_lengths(dataset, split_name=\"train\"):\n",
    "    \"\"\"\n",
    "    Analyze and print text length statistics with histogram.\n",
    "    \n",
    "    Args:\n",
    "        dataset: HuggingFace DatasetDict, Dataset, or DataFrame with 'text' column\n",
    "        split_name: Name of the split for display or to extract from DatasetDict\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistics including mean, median, min, max, std\n",
    "    \"\"\"\n",
    "    if isinstance(dataset, DatasetDict):\n",
    "        df = pd.DataFrame(dataset[split_name])\n",
    "    elif isinstance(dataset, Dataset):\n",
    "        df = pd.DataFrame(dataset)\n",
    "    else:\n",
    "        df = dataset\n",
    "    \n",
    "    text_lengths = df['text'].str.len()\n",
    "    \n",
    "    print(f\"\\nðŸ“ {split_name} Text Length Statistics:\")\n",
    "    print(f\"  Mean: {text_lengths.mean():.0f} characters\")\n",
    "    print(f\"  Median: {text_lengths.median():.0f} characters\")\n",
    "    print(f\"  Min: {text_lengths.min()} characters\")\n",
    "    print(f\"  Max: {text_lengths.max()} characters\")\n",
    "    print(f\"  Std: {text_lengths.std():.0f} characters\")\n",
    "    \n",
    "    print(f\"\\n  Character Length Distribution:\")\n",
    "    max_len = text_lengths.max()\n",
    "    bins = [0, 200, 400, 600, 800, 1000, 1500, 2000]\n",
    "    \n",
    "    # Only add max_len if it's greater than the last bin\n",
    "    if max_len > bins[-1]:\n",
    "        bins.append(max_len)\n",
    "    \n",
    "    hist, bin_edges = np.histogram(text_lengths, bins=bins)\n",
    "    \n",
    "    for i in range(len(hist)):\n",
    "        range_str = f\"  {int(bin_edges[i])}-{int(bin_edges[i+1])}\"\n",
    "        bar = 'â–ˆ' * int(hist[i] / len(df) * 50)  # Scale to 50 chars max\n",
    "        count = hist[i]\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"{range_str:>12}: {bar} {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'mean': text_lengths.mean(),\n",
    "        'median': text_lengths.median(),\n",
    "        'min': text_lengths.min(),\n",
    "        'max': text_lengths.max(),\n",
    "        'std': text_lengths.std()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-lengths",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_text_lengths(raw_dataset, split_name=\"train\")\n",
    "_ = analyze_text_lengths(raw_dataset, split_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-splits",
   "metadata": {},
   "source": [
    "## 6. Create Train/Validation/Test Splits\n",
    "\n",
    "Split the training data to create a validation set for model evaluation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_phishing_dataset(raw_dataset, val_ratio=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare train/val/test splits for phishing detection.\n",
    "    \n",
    "    Args:\n",
    "        raw_dataset: HuggingFace DatasetDict with 'train' and 'test' splits,\n",
    "                    with 'label' column as ClassLabel type\n",
    "        val_ratio: Proportion of training data to use for validation\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        DatasetDict with 'train', 'validation', and 'test' splits\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“Š Original Dataset:\")\n",
    "    print(f\"  Train: {len(raw_dataset['train'])} samples\")\n",
    "    print(f\"  Test: {len(raw_dataset['test'])} samples\")\n",
    "    \n",
    "    print(f\"\\nðŸ”€ Creating stratified train/validation split ({int((1-val_ratio)*100)}/{int(val_ratio*100)})...\")\n",
    "    split_dataset = raw_dataset['train'].train_test_split(\n",
    "        test_size=val_ratio,\n",
    "        stratify_by_column='label',\n",
    "        seed=random_state\n",
    "    )\n",
    "    \n",
    "    train_dataset, validation_dataset, test_dataset = (\n",
    "        split_dataset['train'],\n",
    "        split_dataset['test'],\n",
    "        raw_dataset['test']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Final Dataset Splits:\")\n",
    "    print(f\"  Train: {len(train_dataset)} samples\")\n",
    "    print(f\"  Validation: {len(validation_dataset)} samples\")\n",
    "    print(f\"  Test: {len(test_dataset)} samples\")\n",
    "    print(f\"  Total: {len(train_dataset) + len(validation_dataset) + len(test_dataset)} samples\")\n",
    "    \n",
    "    return DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'validation': validation_dataset,\n",
    "        'test': test_dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPreparing dataset splits...\")\n",
    "dataset = prepare_phishing_dataset(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-datasets",
   "metadata": {},
   "source": [
    "## 7. Save Datasets Locally\n",
    "\n",
    "Export datasets to JSONL format for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-jsonl",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('datasets', exist_ok=True)\n",
    "\n",
    "dataset['train'].to_json('datasets/train.jsonl', lines=True)\n",
    "dataset['validation'].to_json('datasets/validation.jsonl', lines=True)\n",
    "dataset['test'].to_json('datasets/test.jsonl', lines=True)\n",
    "\n",
    "print(\"âœ… Datasets saved locally to ./datasets/\")\n",
    "print(f\"  - train.jsonl: {len(dataset['train'])} samples\")\n",
    "print(f\"  - validation.jsonl: {len(dataset['validation'])} samples\")\n",
    "print(f\"  - test.jsonl: {len(dataset['test'])} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upload-s3",
   "metadata": {},
   "source": [
    "## 8. Upload Datasets to S3\n",
    "\n",
    "Upload processed datasets to S3 for SageMaker training job access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3-upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define S3 paths with consistent structure\n",
    "s3_prefix = \"phishing-detection\"\n",
    "data_s3_uri = f\"s3://{sess.default_bucket()}/{s3_prefix}/data\"\n",
    "\n",
    "train_s3_uri = S3Uploader.upload(\n",
    "    local_path='datasets/train.jsonl',\n",
    "    desired_s3_uri=f\"{data_s3_uri}/train\"\n",
    ")\n",
    "\n",
    "val_s3_uri = S3Uploader.upload(\n",
    "    local_path='datasets/validation.jsonl',\n",
    "    desired_s3_uri=f\"{data_s3_uri}/validation\"\n",
    ")\n",
    "\n",
    "test_s3_uri = S3Uploader.upload(\n",
    "    local_path='datasets/test.jsonl',\n",
    "    desired_s3_uri=f\"{data_s3_uri}/test\"\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“¤ Datasets uploaded to S3:\")\n",
    "print(f\"  Train: {train_s3_uri}\")\n",
    "print(f\"  Validation: {val_s3_uri}\")\n",
    "print(f\"  Test: {test_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "store-variables",
   "metadata": {},
   "source": [
    "## 9. Store Variables for Next Notebook\n",
    "\n",
    "Use IPython's `%store` magic to pass data to the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "store-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store S3 URIs\n",
    "%store train_s3_uri\n",
    "%store val_s3_uri\n",
    "%store test_s3_uri\n",
    "\n",
    "# Store model configuration\n",
    "%store NUM_LABELS\n",
    "%store LABEL_NAMES\n",
    "\n",
    "# Store SageMaker configuration\n",
    "%store region\n",
    "%store role\n",
    "%store sagemaker_session_bucket\n",
    "\n",
    "print(\"\\nâœ… Variables stored successfully!\")\n",
    "print(\"\\nStored variables:\")\n",
    "print(f\"  - train_s3_uri: {train_s3_uri}\")\n",
    "print(f\"  - val_s3_uri: {val_s3_uri}\")\n",
    "print(f\"  - test_s3_uri: {test_s3_uri}\")\n",
    "print(f\"  - NUM_LABELS: {NUM_LABELS}\")\n",
    "print(f\"  - LABEL_NAMES: {LABEL_NAMES}\")\n",
    "print(f\"  - region: {region}\")\n",
    "print(f\"  - sagemaker_session_bucket: {sagemaker_session_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## âœ… Data Processing Complete!\n",
    "\n",
    "### What We Accomplished:\n",
    "1. âœ… Loaded phishing email dataset from HuggingFace\n",
    "2. âœ… Preprocessed email content and converted labels\n",
    "3. âœ… Created stratified train/validation/test splits\n",
    "4. âœ… Analyzed dataset statistics\n",
    "5. âœ… Exported to JSONL format\n",
    "6. âœ… Uploaded to S3\n",
    "7. âœ… Stored variables for next notebook\n",
    "\n",
    "### Next Steps:\n",
    "**Proceed to `02_model_training.ipynb`** to fine-tune the Qwen2.5-1.5B model on this processed data.\n",
    "\n",
    "---\n",
    "\n",
    "**Estimated Time**: ~5-10 minutes  \n",
    "**Estimated Cost**: ~$0.01 (S3 storage only)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
